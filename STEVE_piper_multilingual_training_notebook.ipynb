{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PyEatingContest/corrosive-stones/blob/master/STEVE_piper_multilingual_training_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI-Ia91nNISo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TORCH_FORCE_WEIGHTS_ONLY_LOAD\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o-tM8V68-ubq",
        "outputId": "4f5907f8-5106-4a0c-c208-9bee0212c434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.92.22)] [Connecting to security.ub\r                                                                               \rGet:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://cli.github.com/packages stable/main amd64 Packages [356 B]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,316 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:12 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,885 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,668 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [70.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,971 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,640 kB]\n",
            "Get:21 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [45.0 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,498 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [62.6 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,293 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,604 kB]\n",
            "Get:26 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,288 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
            "Get:29 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.3 kB]\n",
            "Fetched 39.1 MB in 8s (4,727 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3-distutils set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n",
            "  python3.10-minimal\n",
            "Suggested packages:\n",
            "  python3.10-venv python3.10-doc binfmt-support\n",
            "The following packages will be upgraded:\n",
            "  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n",
            "  python3.10 python3.10-minimal\n",
            "6 upgraded, 0 newly installed, 0 to remove and 102 not upgraded.\n",
            "Need to get 12.2 MB of archives.\n",
            "After this operation, 3,072 B of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.13 [4,763 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.13 [1,949 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.13 [508 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.13 [1,850 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.13 [2,272 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.13 [815 kB]\n",
            "Fetched 12.2 MB in 1s (11.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.10-dev_3.10.12-1~22.04.13_amd64.deb ...\n",
            "Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.13) over (3.10.12-1~22.04.12) ...\n",
            "Preparing to unpack .../1-libpython3.10_3.10.12-1~22.04.13_amd64.deb ...\n",
            "Unpacking libpython3.10:amd64 (3.10.12-1~22.04.13) over (3.10.12-1~22.04.12) ...\n",
            "Preparing to unpack .../2-python3.10_3.10.12-1~22.04.13_amd64.deb ...\n",
            "Unpacking python3.10 (3.10.12-1~22.04.13) over (3.10.12-1~22.04.12) ...\n",
            "Preparing to unpack .../3-libpython3.10-stdlib_3.10.12-1~22.04.13_amd64.deb ...\n",
            "Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.13) over (3.10.12-1~22.04.12) ...\n",
            "Preparing to unpack .../4-python3.10-minimal_3.10.12-1~22.04.13_amd64.deb ...\n",
            "Unpacking python3.10-minimal (3.10.12-1~22.04.13) over (3.10.12-1~22.04.12) ...\n",
            "Preparing to unpack .../5-libpython3.10-minimal_3.10.12-1~22.04.13_amd64.deb ...\n",
            "Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.13) over (3.10.12-1~22.04.12) ...\n",
            "Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.13) ...\n",
            "Setting up python3.10-minimal (3.10.12-1~22.04.13) ...\n",
            "Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.13) ...\n",
            "Setting up libpython3.10:amd64 (3.10.12-1~22.04.13) ...\n",
            "Setting up python3.10 (3.10.12-1~22.04.13) ...\n",
            "Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.13) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/python3.10 to provide /usr/bin/python3 (python3) in manual mode\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.10.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.46.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting packaging>=24.0 (from wheel)\n",
            "  Downloading packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.10.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.46.3-py3-none-any.whl (30 kB)\n",
            "Downloading packaging-26.0-py3-none-any.whl (74 kB)\n",
            "Installing collected packages: setuptools, pip, packaging, wheel\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/4\u001b[0m [wheel]\n",
            "\u001b[1A\u001b[2KSuccessfully installed packaging-26.0 pip-25.3 setuptools-80.10.2 wheel-0.46.3\n",
            "Python 3.10.12\n",
            "pip 25.3 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n"
          ]
        }
      ],
      "source": [
        "# 1. Downgrade Python to 3.10\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install python3.10 python3.10-distutils\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "!sudo update-alternatives --set python3 /usr/bin/python3.10\n",
        "\n",
        "# 2. Fix the \"No module named pip\" error by manually installing pip for 3.10\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3\n",
        "\n",
        "# 3. Verify versions - you should see Python 3.10.x and a working pip\n",
        "!python3 --version\n",
        "!pip3 --version\n",
        "\n",
        "# 4. Fix Matplotlib for headless environment\n",
        "import matplotlib\n",
        "matplotlib.use('Agg', force=True)\n",
        "import os\n",
        "os.environ[\"MPLBACKEND\"] = \"Agg\"\n",
        "\n",
        "# 5. Install Piper dependencies using the newly fixed pip\n",
        "!pip3 install -q cython>=0.29.0 piper-phonemize==1.1.0 librosa>=0.9.2 numpy==1.26 onnxruntime>=1.15.0 pytorch-lightning==1.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cHKrI_dM-tl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pathlib\n",
        "\n",
        "# Allow PyTorch to load the specific 'pathlib' objects used in Piper checkpoints\n",
        "torch.serialization.add_safe_globals([pathlib.PosixPath, pathlib.PurePosixPath])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qyxSMuzjfQrz",
        "outputId": "b5115490-d193-45a1-b724-3db0afcc71b0"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}\n",
              "setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ## <font color=\"ffc800\"> **Google Colab Anti-Disconnect.** üîå\n",
        "#@markdown ---\n",
        "#@markdown #### Avoid automatic disconnection. Still, it will disconnect after <font color=\"orange\">**6 to 12 hours**</font>.\n",
        "\n",
        "import IPython\n",
        "js_code = '''\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "'''\n",
        "display(IPython.display.Javascript(js_code))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUNjId07JfAK",
        "outputId": "eb8af999-0fb7-4c11-ee17-437ebd003034"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **Mount Google Drive.** üìÇ\n",
        "#@markdown ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "spIpA-mMA78f",
        "outputId": "07178c14-9a0e-4777-cb8c-b60c26076182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '/content/piper'...\n",
            "remote: Enumerating objects: 2039, done.\u001b[K\n",
            "remote: Counting objects: 100% (152/152), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 2039 (delta 131), reused 125 (delta 125), pack-reused 1887 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2039/2039), 213.36 MiB | 36.92 MiB/s, done.\n",
            "Resolving deltas: 100% (1123/1123), done.\n",
            "/content/piper/src/python\n"
          ]
        }
      ],
      "source": [
        "# 1. Clone the repository so the source files are present on the local disk\n",
        "!git clone https://github.com/rhasspy/piper.git /content/piper\n",
        "\n",
        "# 2. Navigate to the python source directory\n",
        "%cd /content/piper/src/python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHca5kWF_BkI",
        "outputId": "fec1cd9c-2bd7-4cc2-fad5-4e750c9ecab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ PyTorch 2.6 security patch successfully applied to Piper source.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pathlib\n",
        "from functools import wraps\n",
        "\n",
        "# Patch the Piper main file directly to allow 'untrusted' checkpoint loading\n",
        "# We inject this at the top of the actual script so it persists through the run.\n",
        "file_path = '/content/piper/src/python/piper_train/__main__.py'\n",
        "patch_code = \"\"\"\n",
        "import torch\n",
        "import pathlib\n",
        "from functools import wraps\n",
        "torch.serialization.add_safe_globals([pathlib.PosixPath, pathlib.PurePosixPath])\n",
        "_orig_load = torch.load\n",
        "@wraps(_orig_load)\n",
        "def _patched_load(*args, **kwargs):\n",
        "    kwargs['weights_only'] = False\n",
        "    return _orig_load(*args, **kwargs)\n",
        "torch.load = _patched_load\n",
        "\"\"\"\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    content = f.read()\n",
        "with open(file_path, 'w') as f:\n",
        "    f.write(patch_code + \"\\n\" + content)\n",
        "\n",
        "print(\"‚úÖ PyTorch 2.6 security patch successfully applied to Piper source.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfWBuU0_Miem",
        "outputId": "cbb404b6-1ee0-4236-8c41-eb9cd5e9f800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/piper/src/python\n"
          ]
        }
      ],
      "source": [
        "# 1. Navigate to the core source directory\n",
        "%cd /content/piper/src/python\n",
        "\n",
        "# 2. Build the monotonic_align extension\n",
        "# This requires build-essential and python3-dev (usually pre-installed on Colab)\n",
        "!bash build_monotonic_align.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yW5266W2Uuz",
        "outputId": "72a08912-bd7a-451d-b3ab-d26a033f7a26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.10.0\n",
            "Uninstalling torch-2.10.0:\n",
            "  Successfully uninstalled torch-2.10.0\n",
            "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: pytorch-lightning 1.9.0\n",
            "Uninstalling pytorch-lightning-1.9.0:\n",
            "  Successfully uninstalled pytorch-lightning-1.9.0\n",
            "\u001b[33mWARNING: Skipping lightning as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping onnxscript as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: onnxruntime 1.23.2\n",
            "Uninstalling onnxruntime-1.23.2:\n",
            "  Successfully uninstalled onnxruntime-1.23.2\n",
            "\u001b[33mWARNING: Skipping onnx as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Uninstall the problematic new versions\n",
        "!pip uninstall -y torch torchvision torchaudio pytorch-lightning lightning onnxscript onnxruntime onnx\n",
        "\n",
        "# Install the 'Golden Trio' for Piper exports\n",
        "!pip install torch==2.1.0 pytorch-lightning==1.9.0 torchmetrics==0.11.4 onnx==1.16.1 onnxruntime==1.17.1 -q\n",
        "\n",
        "# Patch 1: The math assertion\n",
        "!sed -i 's/assert (discriminant >= 0).all(), discriminant/# assert (discriminant >= 0).all(), discriminant/' /content/piper/src/python/piper_train/vits/transforms.py\n",
        "\n",
        "# Patch 2: The mask guard (adding .detach() helps the tracer ignore the shape check)\n",
        "!sed -i 's/h = self.pre(x0) \\* x_mask/h = self.pre(x0) * x_mask.detach()/' /content/piper/src/python/piper_train/vits/modules.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8J3ZQ7T2bwB",
        "outputId": "55a7f84c-8348-496d-894f-1b18d16eab98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning_fabric/__init__.py:29: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "Removing weight norm...\n",
            "/content/piper/src/python/piper_train/vits/attentions.py:235: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  t_s == t_t\n",
            "/content/piper/src/python/piper_train/vits/attentions.py:295: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  pad_length = max(length - (self.window_size + 1), 0)\n",
            "/content/piper/src/python/piper_train/vits/attentions.py:296: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  slice_start_position = max((self.window_size + 1) - length, 0)\n",
            "/content/piper/src/python/piper_train/vits/attentions.py:298: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if pad_length > 0:\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/jit_utils.py:307: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/symbolic_opset10.py:422: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return g.op(\"Constant\", value_t=torch.tensor(list_or_value))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:702: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:1209: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "INFO:piper_train.export_onnx:Exported model to /content/drive/MyDrive/colab/piper/steven_voice_2744.onnx\n",
            "‚úÖ SUCCESS! File created: /content/drive/MyDrive/colab/piper/steven_voice_2744.onnx\n",
            "üì¶ Size: 60.59 MB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "ckpt_to_export = \"/content/drive/MyDrive/colab/piper/lightning_logs/version_4/checkpoints/epoch=2744-step=2024.ckpt\"\n",
        "output_onnx = \"/content/drive/MyDrive/colab/piper/steven_voice_2744.onnx\"\n",
        "\n",
        "# We use the shell command but set an environment variable to force legacy behavior\n",
        "!export TORCH_ONNX_LOW_LEVEL_DEBUG=1 && \\\n",
        " python3 -m piper_train.export_onnx \"{ckpt_to_export}\" \"{output_onnx}\"\n",
        "\n",
        "if os.path.exists(output_onnx):\n",
        "    print(f\"‚úÖ SUCCESS! File created: {output_onnx}\")\n",
        "    print(f\"üì¶ Size: {os.path.getsize(output_onnx) / 1024**2:.2f} MB\")\n",
        "    !cp /content/drive/MyDrive/colab/piper/config.json \"{output_onnx}.json\"\n",
        "else:\n",
        "    print(\"‚ùå Export still failed. If you see a 'Traceback', paste the very last line here.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6UxlmwObSke"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "export_script_path = '/content/piper/src/python/piper_train/export_onnx.py'\n",
        "\n",
        "# This version checks if it's already patched to avoid infinite recursion\n",
        "export_patch = \"\"\"\n",
        "import torch\n",
        "import pathlib\n",
        "from functools import wraps\n",
        "\n",
        "# Anti-recursion safety: Only patch if torch.load isn't already our patched version\n",
        "if not hasattr(torch, '_is_piper_patched'):\n",
        "    torch.serialization.add_safe_globals([pathlib.PosixPath, pathlib.PurePosixPath])\n",
        "\n",
        "    _orig_load = torch.load\n",
        "    @wraps(_orig_load)\n",
        "    def _patched_load(*args, **kwargs):\n",
        "        kwargs['weights_only'] = False\n",
        "        return _orig_load(*args, **kwargs)\n",
        "\n",
        "    torch.load = _patched_load\n",
        "    torch._is_piper_patched = True\n",
        "\"\"\"\n",
        "\n",
        "# Read the current content\n",
        "with open(export_script_path, 'r') as f:\n",
        "    current_content = f.read()\n",
        "\n",
        "# Only apply the patch if it's not already in the file\n",
        "if \"_is_piper_patched\" not in current_content:\n",
        "    with open(export_script_path, 'w') as f:\n",
        "        f.write(export_patch + current_content)\n",
        "    print(\"‚úÖ Export script patched (with recursion protection).\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Export script was already patched. Skipping to prevent recursion error.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiNiYo0PNbPJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "export_script_path = '/content/piper/src/python/piper_train/export_onnx.py'\n",
        "\n",
        "# This version checks if it's already patched to avoid infinite recursion\n",
        "export_patch = \"\"\"\n",
        "import torch\n",
        "import pathlib\n",
        "from functools import wraps\n",
        "\n",
        "# Anti-recursion safety: Only patch if torch.load isn't already our patched version\n",
        "if not hasattr(torch, '_is_piper_patched'):\n",
        "    torch.serialization.add_safe_globals([pathlib.PosixPath, pathlib.PurePosixPath])\n",
        "\n",
        "    _orig_load = torch.load\n",
        "    @wraps(_orig_load)\n",
        "    def _patched_load(*args, **kwargs):\n",
        "        kwargs['weights_only'] = False\n",
        "        return _orig_load(*args, **kwargs)\n",
        "\n",
        "    torch.load = _patched_load\n",
        "    torch._is_piper_patched = True\n",
        "\"\"\"\n",
        "\n",
        "# Read the current content\n",
        "with open(export_script_path, 'r') as f:\n",
        "    current_content = f.read()\n",
        "\n",
        "# Only apply the patch if it's not already in the file\n",
        "if \"_is_piper_patched\" not in current_content:\n",
        "    with open(export_script_path, 'w') as f:\n",
        "        f.write(export_patch + current_content)\n",
        "    print(\"‚úÖ Export script patched (with recursion protection).\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Export script was already patched. Skipping to prevent recursion error.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJmqZu8QzAV3",
        "outputId": "e0a8d3ef-df2e-45a4-c7eb-0aad07ba7025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnxscript in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.23.2)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.20.1)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.10/dist-packages (from onnxscript) (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.26.0)\n",
            "Requirement already satisfied: onnx_ir<2,>=0.1.12 in /usr/local/lib/python3.10/dist-packages (from onnxscript) (0.1.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxscript) (26.0)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from onnxscript) (4.15.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (6.33.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install onnxscript onnxruntime onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioA4Sr-4zBtf",
        "outputId": "b6ca282c-bbf0-4e20-eaf8-e96e56d531e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Patched transforms.py to bypass the export guard.\n"
          ]
        }
      ],
      "source": [
        "# This comments out the line that is causing the TorchExportError\n",
        "!sed -i 's/assert (discriminant >= 0).all(), discriminant/# assert (discriminant >= 0).all(), discriminant/' /content/piper/src/python/piper_train/vits/transforms.py\n",
        "\n",
        "print(\"‚úÖ Patched transforms.py to bypass the export guard.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kinGr7_60EFB"
      },
      "outputs": [],
      "source": [
        "# This patches the specific line in modules.py identified in your error log\n",
        "!sed -i '449s/h = self.pre(x0) \\* x_mask/# h = self.pre(x0) * x_mask/' /content/piper/src/python/piper_train/vits/modules.py\n",
        "# Note: Since the error suggested inserting a check, we can also try to simply\n",
        "# satisfy the exporter by forcing a dummy check, but commenting out is often cleaner for export."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8XiOi7V0Jbt",
        "outputId": "258b56c8-f156-4f6b-84b6-0c7b183c9366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.1.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m  \u001b[33m0:00:53\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.16.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m156.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.1.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2026.1.0)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0) (1.26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0) (2.32.5)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.0)\n",
            "  Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.1.0) (2.0.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, pillow, torch, torchvision, torchaudio\n",
            "\u001b[2K  Attempting uninstall: triton\n",
            "\u001b[2K    Found existing installation: triton 3.6.0\n",
            "\u001b[2K    Uninstalling triton-3.6.0:\n",
            "\u001b[2K      Successfully uninstalled triton-3.6.0\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 2.10.0\n",
            "\u001b[2K    Uninstalling torch-2.10.0:\n",
            "\u001b[2K      Successfully uninstalled torch-2.10.0\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/5\u001b[0m [torchaudio]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pillow-12.0.0 torch-2.1.0+cu121 torchaudio-2.1.0+cu121 torchvision-0.16.0+cu121 triton-2.1.0\n",
            "Collecting onnxscript==0.1.0\n",
            "  Downloading onnxscript-0.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting onnxruntime==1.16.3\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting onnx==1.15.0\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxscript==0.1.0) (1.26.0)\n",
            "INFO: pip is looking at multiple versions of onnxscript to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install onnx==1.15.0 and onnxscript==0.1.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested onnx==1.15.0\n",
            "    onnxscript 0.1.0 depends on onnx>=1.16\n",
            "\n",
            "Additionally, some packages in these conflicts have no matching distributions available for your environment:\n",
            "    onnx\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install onnxscript==0.1.0 onnxruntime==1.16.3 onnx==1.15.0‚Äì‚Äì"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "t_wcH8eQ_j60",
        "outputId": "f3013514-4522-4120-f1ee-bdb5d43e857b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: onnxscript 0.5.7\n",
            "Uninstalling onnxscript-0.5.7:\n",
            "  Successfully uninstalled onnxscript-0.5.7\n",
            "Found existing installation: onnxruntime 1.23.2\n",
            "Uninstalling onnxruntime-1.23.2:\n",
            "  Successfully uninstalled onnxruntime-1.23.2\n",
            "Found existing installation: onnx 1.20.1\n",
            "Uninstalling onnx-1.20.1:\n",
            "  Successfully uninstalled onnx-1.20.1\n",
            "Collecting onnx==1.16.1\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime==1.17.1\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx==1.16.1) (1.26.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx==1.16.1) (6.33.4)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.17.1) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.17.1) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.17.1) (26.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.17.1) (1.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime==1.17.1) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.17.1) (1.3.0)\n",
            "Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, onnxruntime\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [onnxruntime]\n",
            "\u001b[1A\u001b[2KSuccessfully installed onnx-1.16.1 onnxruntime-1.17.1\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytorch_lightning'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2363351288.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/piper/src/python\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpiper_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_onnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Re-run the export but we'll modify the command to ensure dynamo is OFF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/piper/src/python/piper_train/export_onnx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVitsModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0m_LOGGER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"piper_train.export_onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/piper/src/python/piper_train/vits/lightning.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 1. Clean up and install only what we need for legacy export\n",
        "!pip uninstall -y onnxscript onnxruntime onnx\n",
        "!pip install onnx==1.16.1 onnxruntime==1.17.1\n",
        "\n",
        "# 2. Patch the Piper code (One last time to be sure)\n",
        "# This removes the assertion and the mask guard that caused your previous u14/u18 errors\n",
        "!sed -i 's/assert (discriminant >= 0).all(), discriminant/# assert (discriminant >= 0).all(), discriminant/' /content/piper/src/python/piper_train/vits/transforms.py\n",
        "!sed -i 's/h = self.pre(x0) \\* x_mask/h = self.pre(x0) * x_mask.detach()/' /content/piper/src/python/piper_train/vits/modules.py\n",
        "\n",
        "# 3. Force the Legacy Export Path\n",
        "# We set dynamo=False to tell PyTorch \"Stop trying to be smart, just trace the graph.\"\n",
        "import torch\n",
        "import sys\n",
        "sys.path.append(\"/content/piper/src/python\")\n",
        "from piper_train.export_onnx import main\n",
        "\n",
        "# Re-run the export but we'll modify the command to ensure dynamo is OFF\n",
        "ckpt_to_export = \"/content/drive/MyDrive/colab/piper/lightning_logs/version_4/checkpoints/epoch=2744-step=2024.ckpt\"\n",
        "output_onnx = \"/content/drive/MyDrive/colab/piper/steven_voice_2744.onnx\"\n",
        "\n",
        "# Run the export script directly via shell to keep it simple\n",
        "!python3 -m piper_train.export_onnx \"{ckpt_to_export}\" \"{output_onnx}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhF81akJzFmO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b9iqBIPAUqf"
      },
      "outputs": [],
      "source": [
        "*** OLDER CODE BELOW ***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE4ZQMGf_TFp",
        "outputId": "6764904c-8bfe-4972-f140-b764a80c53eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (3.10.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/site-packages (from matplotlib) (2.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib) (12.1.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.11/site-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "‚ú®üç∞‚ú® Everything looks OK!\n",
            "Current Matplotlib backend: Agg\n"
          ]
        }
      ],
      "source": [
        "# Clean up any redisual older piper code\n",
        "!rm -rf /content/piper\n",
        "\n",
        "# Load an older python to run the training\n",
        "!pip install -q condacolab\n",
        "!pip install matplotlib\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "import os\n",
        "import matplotlib\n",
        "\n",
        "# 1. Clear any existing backend environment variable\n",
        "os.environ.pop(\"MPLBACKEND\", None)\n",
        "\n",
        "# 2. Reset Matplotlib to its defaults\n",
        "matplotlib.rcdefaults()\n",
        "\n",
        "# 3. Force the 'Agg' backend (headless/non-GUI)\n",
        "matplotlib.use('Agg', force=True)\n",
        "\n",
        "# 4. Verify the change\n",
        "print(f\"Current Matplotlib backend: {matplotlib.get_backend()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AICh6p5OJybj"
      },
      "source": [
        "# <font color=\"ffc800\">üîß ***First steps.*** üîß"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ygxzp-xHTC7T",
        "outputId": "01ac8e13-7eff-48ed-bdf7-42b8e1990350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jan 25 22:43:49 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#@markdown ## <font color=\"ffc800\"> **Check GPU type.** üëÅÔ∏è\n",
        "#@markdown ---\n",
        "#@markdown #### A higher capable GPU can lead to faster training speeds. By default, you will have a <font color=\"orange\">**Tesla T4**</font>.\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_XwmTVlcUgCh",
        "outputId": "e4b239fc-fbff-4d80-a809-d9eea2417715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/piper/src/python\n",
            "Collecting gdown\n",
            "  Downloading gdown-5.2.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting beautifulsoup4 (from gdown)\n",
            "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from gdown) (3.20.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/site-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from gdown) (4.67.1)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (1.26.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2026.1.15-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
            "  Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2026.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting soupsieve>=1.6.1 (from beautifulsoup4->gdown)\n",
            "  Downloading soupsieve-2.8.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests[socks]->gdown) (2024.12.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading gdown-5.2.1-py3-none-any.whl (18 kB)\n",
            "Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2026.1.15-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
            "Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
            "Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soupsieve-2.8.3-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: soupsieve, safetensors, regex, hf-xet, huggingface-hub, beautifulsoup4, tokenizers, gdown, transformers\n",
            "Successfully installed beautifulsoup4-4.14.3 gdown-5.2.1 hf-xet-1.2.0 huggingface-hub-0.36.0 regex-2026.1.15 safetensors-0.7.0 soupsieve-2.8.3 tokenizers-0.22.2 transformers-4.57.6\n",
            "Compiling /content/piper/src/python/piper_train/vits/monotonic_align/core.pyx because it changed.\n",
            "[1/1] Cythonizing /content/piper/src/python/piper_train/vits/monotonic_align/core.pyx\n",
            "performance hint: core.pyx:5:0: Exception check on 'maximum_path_each' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_each' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_each' to allow an error code to be returned.\n",
            "performance hint: core.pyx:36:0: Exception check on 'maximum_path_c' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_c' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_c' to allow an error code to be returned.\n",
            "performance hint: core.pyx:42:21: Exception check after calling 'maximum_path_each' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_each' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_each' to allow an error code to be returned.\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **Install software.** üì¶\n",
        "#@markdown ---\n",
        "#@markdown ####In this cell the synthesizer and its necessary dependencies to execute the training will be installed. (this may take a while)\n",
        "\n",
        "# clone:\n",
        "!git clone -q https://github.com/rmcpantoja/piper\n",
        "%cd /content/piper/src/python\n",
        "!wget -q \"https://raw.githubusercontent.com/coqui-ai/TTS/dev/TTS/bin/resample.py\"\n",
        "#!pip install -q -r requirements.txt\n",
        "!pip install -q cython>=0.29.0 piper-phonemize==1.1.0 librosa>=0.9.2 numpy==1.26 onnxruntime>=1.15.0 pytorch-lightning\n",
        "!pip install --upgrade gdown transformers\n",
        "!bash build_monotonic_align.sh\n",
        "# Useful vars:\n",
        "use_whisper = True\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TSiGgfidBHHn",
        "outputId": "6708de02-44b7-47a6-d47a-3a78b53ced6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: piper-phonemize-cross in /usr/local/lib/python3.11/site-packages (1.2.1)\n",
            "/content/piper/src/python\n",
            "Obtaining file:///content/piper/src/python\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: pytorch-lightning==1.9.0 in /usr/local/lib/python3.11/site-packages (1.9.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/site-packages (1.23.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/site-packages (from pytorch-lightning==1.9.0) (1.26.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/site-packages (from pytorch-lightning==1.9.0) (2.10.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/site-packages (from pytorch-lightning==1.9.0) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/site-packages (from pytorch-lightning==1.9.0) (6.0.3)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.11/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (2026.1.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/site-packages (from pytorch-lightning==1.9.0) (1.8.2)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/site-packages (from pytorch-lightning==1.9.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/site-packages (from pytorch-lightning==1.9.0) (4.15.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.4.2 in /usr/local/lib/python3.11/site-packages (from pytorch-lightning==1.9.0) (0.15.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/site-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/site-packages (from onnxruntime) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/site-packages (from onnxruntime) (6.33.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from onnxruntime) (1.14.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (3.13.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from lightning-utilities>=0.4.2->pytorch-lightning==1.9.0) (65.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.20.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.11/site-packages (from cuda-bindings==12.9.4->torch>=1.10.0->pytorch-lightning==1.9.0) (1.3.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->pytorch-lightning==1.9.0) (3.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (3.10)\n"
          ]
        }
      ],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **Install older cross-compatible version of software.** üì¶\n",
        "# 1. Install the cross-compatible version\n",
        "!pip install piper-phonemize-cross\n",
        "\n",
        "# 2. Re-install Piper without the strict dependency check\n",
        "%cd /content/piper/src/python\n",
        "!pip install -e . --no-deps\n",
        "!pip install pytorch-lightning==1.9.0 onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEqgH3FJBoxp",
        "outputId": "92942884-65ee-4a10-d97e-4439a27adec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå Still missing something: No module named 'piper_train'\n"
          ]
        }
      ],
      "source": [
        "# Check thank the machine can access the piper modules\n",
        "import sys\n",
        "sys.path.append('/content/piper/src/python')\n",
        "\n",
        "try:\n",
        "    from piper_train.vits import commons\n",
        "    print(\"‚úÖ Piper training modules are now accessible!\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Still missing something: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiMxFEDgGMve",
        "outputId": "45fc5e61-b4f2-4d1a-c357-976a7b724ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Global Torch patch applied to Piper source.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "file_path = '/content/piper/src/python/piper_train/__main__.py'\n",
        "\n",
        "# The code we want to inject at the very top of the file\n",
        "patch_code = \"\"\"\n",
        "import torch\n",
        "import pathlib\n",
        "from functools import wraps\n",
        "\n",
        "# Add specific safe globals\n",
        "torch.serialization.add_safe_globals([pathlib.PosixPath, pathlib.PurePosixPath])\n",
        "\n",
        "# Force weights_only=False globally for this process\n",
        "_orig_load = torch.load\n",
        "@wraps(_orig_load)\n",
        "def _patched_load(*args, **kwargs):\n",
        "    kwargs['weights_only'] = False\n",
        "    return _orig_load(*args, **kwargs)\n",
        "torch.load = _patched_load\n",
        "\"\"\"\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    original_content = f.read()\n",
        "\n",
        "# Write the patch at the top\n",
        "with open(file_path, 'w') as f:\n",
        "    f.write(patch_code + \"\\n\" + original_content)\n",
        "\n",
        "print(\"‚úÖ Global Torch patch applied to Piper source.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr_UhhxLdtMJ",
        "outputId": "1ec9c119-1afa-49bc-c31b-b802ae3c6ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/piper/src/python/piper_train/export_onnx.py\", line 111, in <module>\n",
            "    main()\n",
            "  File \"/content/piper/src/python/piper_train/export_onnx.py\", line 42, in main\n",
            "    model = VitsModel.load_from_checkpoint(args.checkpoint, dataset=None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/pytorch_lightning/core/saving.py\", line 139, in load_from_checkpoint\n",
            "    return _load_from_checkpoint(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/pytorch_lightning/core/saving.py\", line 160, in _load_from_checkpoint\n",
            "    checkpoint = pl_load(checkpoint_path, map_location=map_location)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/lightning_fabric/utilities/cloud_io.py\", line 48, in _load\n",
            "    return torch.load(f, map_location=map_location)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/torch/serialization.py\", line 1548, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL pathlib.PosixPath was not an allowed global by default. Please use `torch.serialization.add_safe_globals([pathlib.PosixPath])` or the `torch.serialization.safe_globals([pathlib.PosixPath])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "‚úÖ Export complete! Your files are ready in Drive: \n",
            "1. /content/drive/MyDrive/colab/piper/steven_voice_2744.onnx \n",
            "2. /content/drive/MyDrive/colab/piper/steven_voice_2744.onnx.json\n"
          ]
        }
      ],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **Export a trained version of the model.** üì¶\n",
        "\n",
        "# Define paths for your specific checkpoint and output\n",
        "ckpt_path = \"/content/drive/MyDrive/colab/piper/lightning_logs/version_4/checkpoints/epoch=2744-step=2024.ckpt\"\n",
        "output_onnx = \"/content/drive/MyDrive/colab/piper/steven_voice_2744.onnx\"\n",
        "\n",
        "# Run the export module\n",
        "!python3 -m piper_train.export_onnx \\\n",
        "    \"{ckpt_path}\" \\\n",
        "    \"{output_onnx}\"\n",
        "\n",
        "# Ensure the config file is also copied and named correctly\n",
        "!cp /content/drive/MyDrive/colab/piper/config.json \"{output_onnx}.json\"\n",
        "\n",
        "print(f\"‚úÖ Export complete! Your files are ready in Drive: \\n1. {output_onnx} \\n2. {output_onnx}.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3bMzEE0V5Ma"
      },
      "source": [
        "# <font color=\"ffc800\"> ü§ñ ***Training.*** ü§ñ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvEGjf0aV8eg",
        "outputId": "670cc062-9717-4a52-b200-2f99b52ae3a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/dataset\n",
            "Unzipping audio content...\n",
            "replace /content/dataset/wavs/0000000135.wav? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "/content/dataset/wavs\n",
            "Opened dataset with 151 wavs with duration 0:20:23.\n",
            "/content/dataset\n"
          ]
        }
      ],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **1. Extract dataset.** üì•\n",
        "#@markdown ---\n",
        "#@markdown ####Important: the audios must be in <font color=\"orange\">**wav format, (16000 or 22050hz, 16-bits, mono), and, for convenience, numbered. Example:**\n",
        "\n",
        "#@markdown * <font color=\"orange\">**1.wav**</font>\n",
        "#@markdown * <font color=\"orange\">**2.wav**</font>\n",
        "#@markdown * <font color=\"orange\">**3.wav**</font>\n",
        "#@markdown * <font color=\"orange\">**.....**</font>\n",
        "\n",
        "#@markdown ---\n",
        "import os\n",
        "import wave\n",
        "import zipfile\n",
        "import datetime\n",
        "\n",
        "def get_dataset_duration(wav_path):\n",
        "    totalduration = 0\n",
        "    for file_name in [x for x in os.listdir(wav_path) if os.path.isfile(x) and \".wav\" in x]:\n",
        "        with wave.open(file_name, \"rb\") as wave_file:\n",
        "            frames = wave_file.getnframes()\n",
        "            rate = wave_file.getframerate()\n",
        "            duration = frames / float(rate)\n",
        "            totalduration += duration\n",
        "    wav_count = len(os.listdir(wav_path))\n",
        "    duration_str = str(datetime.timedelta(seconds=round(totalduration, 0)))\n",
        "    return wav_count, duration_str\n",
        "\n",
        "%cd /content\n",
        "if not os.path.exists(\"/content/dataset\"):\n",
        "    os.makedirs(\"/content/dataset\")\n",
        "    os.makedirs(\"/content/dataset/wavs\")\n",
        "%cd /content/dataset\n",
        "#@markdown ### Audio dataset path to unzip:\n",
        "zip_path = \"/content/drive/MyDrive/piper_dataset.zip\" #@param {type:\"string\"}\n",
        "zip_path = zip_path.strip()\n",
        "if zip_path:\n",
        "    if os.path.exists(zip_path):\n",
        "        if zipfile.is_zipfile(zip_path):\n",
        "            print(\"Unzipping audio content...\")\n",
        "            !unzip -q -j \"{zip_path}\" -d /content/dataset/wavs\n",
        "        else:\n",
        "            print(\"Copying audio contents of this folder...\")\n",
        "            fp = zip_path + \"/.\"\n",
        "            !cp -a \"$fp\" \"/content/dataset/wavs\"\n",
        "    else:\n",
        "        raise Exception(\"The path provided to the wavs is not correct. Please set a valid path.\")\n",
        "else:\n",
        "    raise Exception(\"You must provide with a path to the wavs.\")\n",
        "if os.path.exists(\"/content/dataset/wavs/wavs\"):\n",
        "    for file in os.listdir(\"/content/dataset/wavs/wavs\"):\n",
        "        !mv /content/dataset/wavs/wavs/\"$file\"  /content/dataset/wavs/\"$file\"\n",
        "    !rm -r /content/dataset/wavs/*.txt\n",
        "    !rm -r /content/dataset/wavs/*.csv\n",
        "%cd /content/dataset/wavs\n",
        "audio_count, dataset_dur = get_dataset_duration(\"/content/dataset/wavs\")\n",
        "print(f\"Opened dataset with {audio_count} wavs with duration {dataset_dur}.\")\n",
        "%cd ..\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "E0W0OCvXXvue",
        "outputId": "0f35ed73-02c5-43da-c7f5-9f9bf631b573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/dataset\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-171062b0-6e73-408e-b317-74e5e4e1ba5f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-171062b0-6e73-408e-b317-74e5e4e1ba5f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving metadata.csv to metadata.csv\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **2. Upload the transcript file.** üìù\n",
        "#@markdown ---\n",
        "#@markdown ####<font color=\"orange\">**Important: the transcription means writing what the character says in each of the audios, and it must have the following structure:**\n",
        "\n",
        "#@markdown ##### <font color=\"orange\">For a single-speaker dataset:\n",
        "#@markdown * wavs/1.wav|This is what my character says in audio 1.\n",
        "#@markdown * wavs/2.wav|This, the text that the character says in audio 2.\n",
        "#@markdown * ...\n",
        "\n",
        "#@markdown ##### <font color=\"orange\">For a multi-speaker dataset:\n",
        "\n",
        "#@markdown * wavs/speaker1audio1.wav|speaker1|This is what the first speaker says.\n",
        "#@markdown * wavs/speaker1audio2.wav|speaker1|This is another audio of the first speaker.\n",
        "#@markdown * wavs/speaker2audio1.wav|speaker2|This is what the second speaker says in the first audio.\n",
        "#@markdown * wavs/speaker2audio2.wav|speaker2|This is another audio of the second speaker.\n",
        "#@markdown * ...\n",
        "\n",
        "#@markdown And so on. In addition, the transcript must be in a <font color=\"orange\">**.csv or .txt format. (UTF-8 without BOM)**\n",
        "\n",
        "#@markdown ## Auto-transcribe with whisper if transcription is not provided.\n",
        "\n",
        "#@markdown **Note: If you don't upload any transcription files, the wavs will be transcribed using the whisper tool when you execute the next step. Then, the notebook will continue with the rest of the preprocessing if there are no errors. Although the Whisper tool has good transcription results, in my experience I recommend transcribing manually and uploading it from this cell, since a good TTS voice needs to be optimized to give even better results. For example, when transcribing manually you will be able to observe every detail that the speaker makes (such as punctuation, sounds, etc.), and capture them in the transcription according to the speaker's intonations.**\n",
        "\n",
        "\n",
        "#@markdown However, if you want to transcribe and review this transcription, you can use the individual notebooks:\n",
        "\n",
        "#@markdown * [English](http://colab.research.google.com/github/rmcpantoja/My-Colab-Notebooks/blob/main/notebooks/OpenAI_Whisper_-_DotCSV_(Speech_dataset_multi-transcryption_support)en.ipynb)\n",
        "#@markdown * [French](http://colab.research.google.com/github/rmcpantoja/My-Colab-Notebooks/blob/main/notebooks/OpenAI_Whisper_-_DotCSV_(Speech_dataset_multi-transcryption_support)fr.ipynb)\n",
        "#@markdown * [Spanish](http://colab.research.google.com/github/rmcpantoja/My-Colab-Notebooks/blob/main/notebooks/OpenAI_Whisper_-_DotCSV_(Speech_dataset_multi-transcryption_support)es.ipynb)\n",
        "\n",
        "#@markdown ---\n",
        "%cd /content/dataset\n",
        "from google.colab import files\n",
        "!rm /content/dataset/metadata.csv\n",
        "\n",
        "if os.path.exists(\"/content/dataset/wavs/_transcription.txt\"):\n",
        "  !mv \"/content/dataset/wavs/_transcription.txt\" metadata.csv\n",
        "else:\n",
        "  listfn, length = files.upload().popitem()\n",
        "  if listfn != \"metadata.csv\":\n",
        "    !mv \"$listfn\" metadata.csv\n",
        "\n",
        "use_whisper = False\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOyx9Y6JYvRF",
        "outputId": "1f9040a4-d600-49f2-988a-48d8a8d7924b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/piper/src/python\n",
            "INFO:preprocess:Single speaker dataset\n",
            "INFO:preprocess:Wrote dataset config\n",
            "INFO:preprocess:Processing 150 utterance(s) with 2 worker(s)\n",
            "Preprocessing done!\n"
          ]
        }
      ],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **3. Preprocess dataset.** üîÑ\n",
        "#@markdown ---\n",
        "import os\n",
        "if use_whisper:\n",
        "    import torch\n",
        "    from faster_whisper import WhisperModel\n",
        "    from tqdm import tqdm\n",
        "    from google import colab\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    def make_dataset(path, language):\n",
        "        metadata = \"\"\n",
        "        text = \"\"\n",
        "        files = [f for f in os.listdir(path) if f.endswith(\".wav\")]\n",
        "        assert len(files) > 0, \"You don't have wavs uploaded either! Please upload at least one zip with the wavs in step 2.\"\n",
        "        metadata_file = open(f\"{path}/../metadata.csv\", \"w\")\n",
        "        whisper = WhisperModel(\"large-v3\", device=device, compute_type=\"float16\")\n",
        "        for audio_file in tqdm(files):\n",
        "            full_path = os.path.join(path, audio_file)\n",
        "            segments, _ = whisper.transcribe(full_path, word_timestamps=False, language=language)\n",
        "            for segment in segments:\n",
        "                text += segment.text\n",
        "            text = text.strip()\n",
        "            text = text.replace('\\n', ' ')\n",
        "            metadata = f\"{audio_file}|{text}\\n\"\n",
        "            metadata_file.write(metadata)\n",
        "            text = \"\"\n",
        "        colab.files.download(f\"{path}/../metadata.csv\")\n",
        "        del whisper\n",
        "        return True\n",
        "\n",
        "#@markdown ### First of all, select the language of your dataset.\n",
        "language = \"English (U.S.)\" #@param [\"ÿ£ŸÑÿπŸéÿ±Ÿéÿ®ŸêŸä\", \"Catal√†\", \"ƒçe≈°tina\", \"Dansk\", \"Deutsch\", \"ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨\", \"English (British)\", \"English (U.S.)\", \"Espa√±ol (Castellano)\", \"Espa√±ol (Latinoamericano)\", \"Suomi\", \"Fran√ßais\", \"Magyar\", \"Icelandic\", \"Italiano\", \"·É•·Éê·É†·Éó·É£·Éö·Éò\", \"“õ–∞–∑–∞“õ—à–∞\", \"L√´tzebuergesch\", \"‡§®‡•á‡§™‡§æ‡§≤‡•Ä\", \"Nederlands\", \"Norsk\", \"Polski\", \"Portugu√™s (Brasil)\", \"Portugu√™s (Portugal)\", \"Rom√¢nƒÉ\", \"–†—É—Å—Å–∫–∏–π\", \"–°—Ä–ø—Å–∫–∏\", \"Svenska\", \"Kiswahili\", \"T√ºrk√ße\", \"—É–∫—Ä–∞—óÃÅ–Ω—Å—å–∫–∞\", \"Ti·∫øng Vi·ªát\", \"ÁÆÄ‰Ωì‰∏≠Êñá\"]\n",
        "#@markdown ---\n",
        "# language definition:\n",
        "languages = {\n",
        "    \"ÿ£ŸÑÿπŸéÿ±Ÿéÿ®ŸêŸä\": \"ar\",\n",
        "    \"Catal√†\": \"ca\",\n",
        "    \"ƒçe≈°tina\": \"cs\",\n",
        "    \"Dansk\": \"da\",\n",
        "    \"Deutsch\": \"de\",\n",
        "    \"ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨\": \"el\",\n",
        "    \"English (British)\": \"en\",\n",
        "    \"English (U.S.)\": \"en-us\",\n",
        "    \"Espa√±ol (Castellano)\": \"es\",\n",
        "    \"Espa√±ol (Latinoamericano)\": \"es-419\",\n",
        "    \"Suomi.\": \"fi\",\n",
        "    \"Fran√ßais\": \"fr\",\n",
        "    \"Magyar\": \"hu\",\n",
        "    \"Icelandic\": \"is\",\n",
        "    \"Italiano\": \"it\",\n",
        "    \"·É•·Éê·É†·Éó·É£·Éö·Éò\": \"ka\",\n",
        "    \"“õ–∞–∑–∞“õ—à–∞\": \"kk\",\n",
        "    \"L√´tzebuergesch\": \"lb\",\n",
        "    \"‡§®‡•á‡§™‡§æ‡§≤‡•Ä\": \"ne\",\n",
        "    \"Nederlands\": \"nl\",\n",
        "    \"Norsk\": \"nb\",\n",
        "    \"Polski\": \"pl\",\n",
        "    \"Portugu√™s (Brasil)\": \"pt-br\",\n",
        "    \"Portugu√™s (Portugal)\": \"pt-pt\",\n",
        "    \"Rom√¢nƒÉ\": \"ro\",\n",
        "    \"–†—É—Å—Å–∫–∏–π\": \"ru\",\n",
        "    \"–°—Ä–ø—Å–∫–∏\": \"sr\",\n",
        "    \"Svenska\": \"sv\",\n",
        "    \"Kiswahili\": \"sw\",\n",
        "    \"T√ºrk√ße\": \"tr\",\n",
        "    \"—É–∫—Ä–∞—óÃÅ–Ω—Å—å–∫–∞\": \"uk\",\n",
        "    \"Ti·∫øng Vi·ªát\": \"vi\",\n",
        "    \"ÁÆÄ‰Ωì‰∏≠Êñá\": \"zh\"\n",
        "}\n",
        "\n",
        "def _get_language(code):\n",
        "    return languages[code]\n",
        "\n",
        "final_language = _get_language(language)\n",
        "#@markdown ### Choose a name for your model:\n",
        "model_name = \"\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "# output:\n",
        "#@markdown ### Choose the working folder: (recommended to save to Drive)\n",
        "\n",
        "#@markdown The working folder will be used in preprocessing, but also in training the model.\n",
        "output_path = \"/content/drive/MyDrive/colab/piper\" #@param {type:\"string\"}\n",
        "output_dir = output_path+\"/\"+model_name\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "#@markdown ---\n",
        "#@markdown ### Choose dataset format:\n",
        "dataset_format = \"ljspeech\" #@param [\"ljspeech\", \"mycroft\"]\n",
        "#@markdown ---\n",
        "#@markdown ### Is this a single speaker dataset? Otherwise, uncheck:\n",
        "single_speaker = True #@param {type:\"boolean\"}\n",
        "if single_speaker:\n",
        "  force_sp = \" --single-speaker\"\n",
        "else:\n",
        "  force_sp = \"\"\n",
        "#@markdown ---\n",
        "#@markdown ### Select the sample rate of the dataset:\n",
        "sample_rate = \"22050\" #@param [\"16000\", \"22050\"]\n",
        "#@markdown ---\n",
        "# creating paths:\n",
        "if not os.path.exists(\"/content/audio_cache\"):\n",
        "    os.makedirs(\"/content/audio_cache\")\n",
        "%cd /content/piper/src/python\n",
        "#@markdown ### Do you want to train using this sample rate, but your audios don't have it?\n",
        "#@markdown The resampler helps you do it quickly!\n",
        "resample = False #@param {type:\"boolean\"}\n",
        "if resample:\n",
        "  !python resample.py --input_dir \"/content/dataset/wavs\" --output_dir \"/content/dataset/wavs_resampled\" --output_sr {sample_rate} --file_ext \"wav\"\n",
        "  !mv /content/dataset/wavs_resampled/* /content/dataset/wavs\n",
        "#@markdown ---\n",
        "# check transcription:\n",
        "if use_whisper:\n",
        "    print(\"Transcript file hasn't been uploaded. Transcribing these audios using Whisper...\")\n",
        "    make_dataset(\"/content/dataset/wavs\", final_language[:2])\n",
        "    print(\"Transcription done! Pre-processing...\")\n",
        "!python -m piper_train.preprocess \\\n",
        "  --language {final_language} \\\n",
        "  --input-dir /content/dataset \\\n",
        "  --cache-dir \"/content/audio_cache\" \\\n",
        "  --output-dir \"{output_dir}\" \\\n",
        "  --dataset-name \"{model_name}\" \\\n",
        "  --dataset-format {dataset_format} \\\n",
        "  --sample-rate {sample_rate} \\\n",
        "  {force_sp}\n",
        "print(\"Preprocessing done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ickQlOCRjkBL",
        "outputId": "47792546-09f7-4cd7-b52c-5662abd0d98f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[93mModel downloaded!\n"
          ]
        }
      ],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **4. Settings.** üß∞\n",
        "#@markdown ---\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from google.colab import output\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "#@markdown ### <font color=\"orange\">**Select the action to train this dataset: (READ CAREFULLY)**\n",
        "\n",
        "#@markdown * The option to <font color=\"orange\">continue a training</font> is self-explanatory. If you've previously trained a model with free colab, your time is up and you're considering training it some more, this is ideal for you. You just have to set the same settings that you set when you first trained this model.\n",
        "#@markdown * The option to <font color=\"orange\">convert a single-speaker model to a multi-speaker model</font> is self-explanatory, and for this it is important that you have processed a dataset that contains text and audio from all possible speakers that you want to train in your model.\n",
        "#@markdown * The <font color=\"orange\">finetune</font> option is used to train a dataset using a pretrained model, that is, train on that data. This option is ideal if you want to train a very small dataset (more than five minutes recommended).\n",
        "#@markdown * The <font color=\"orange\">train from scratch</font> option builds features such as dictionary and speech form from scratch, and this may take longer to converge. For this, hours of audio (8 at least) are recommended, which have a large collection of phonemes.\n",
        "\n",
        "action = \"finetune\" #@param [\"Continue training\", \"convert single-speaker to multi-speaker model\", \"finetune\", \"train from scratch\"]\n",
        "#@markdown ---\n",
        "if action == \"Continue training\":\n",
        "    checkpoints = glob.glob(f\"{output_dir}/lightning_logs/**/checkpoints/last.ckpt\", recursive=True)\n",
        "    if len(checkpoints):\n",
        "        last_checkpoint = sorted(checkpoints, key=lambda x: int(re.findall(r'version_(\\d+)', x)[0]))[-1]\n",
        "        ft_command = f'--resume_from_checkpoint \"{last_checkpoint}\" '\n",
        "        print(f\"Continuing {model_name}'s training at: {last_checkpoint}\")\n",
        "    else:\n",
        "        raise Exception(\"Training cannot be continued as there is no checkpoint to continue at.\")\n",
        "elif action == \"finetune\":\n",
        "    if os.path.exists(f\"{output_dir}/lightning_logs/version_0/checkpoints/last.ckpt\"):\n",
        "        raise Exception(\"Oh no! You have already trained this model before, you cannot choose this option since your progress will be lost, and then your previous time will not count. Please select the option to continue a training.\")\n",
        "    else:\n",
        "        ft_command = '--resume_from_checkpoint \"/content/pretrained.ckpt\" '\n",
        "elif action == \"convert single-speaker to multi-speaker model\":\n",
        "    if not single_speaker:\n",
        "        ft_command = '--resume_from_single_speaker_checkpoint \"/content/pretrained.ckpt\" '\n",
        "    else:\n",
        "        raise Exception(\"This dataset is not a multi-speaker dataset!\")\n",
        "else:\n",
        "    ft_command = \"\"\n",
        "if action== \"convert single-speaker to multi-speaker model\" or action == \"finetune\":\n",
        "    try:\n",
        "        with open('/content/piper/notebooks/pretrained_models.json') as f:\n",
        "            pretrained_models = json.load(f)\n",
        "        if final_language in pretrained_models:\n",
        "            models = pretrained_models[final_language]\n",
        "            model_options = [(model_name, model_name) for model_name, model_url in models.items()]\n",
        "            model_dropdown = widgets.Dropdown(description = \"Choose pretrained model\", options=model_options)\n",
        "            download_button = widgets.Button(description=\"Download\")\n",
        "            def download_model(btn):\n",
        "                model_name = model_dropdown.value\n",
        "                model_url = pretrained_models[final_language][model_name]\n",
        "                print(\"\\033[93mDownloading pretrained model...\")\n",
        "                if model_url.startswith(\"1\"):\n",
        "                    !gdown -q \"{model_url}\" -O \"/content/pretrained.ckpt\"\n",
        "                elif model_url.startswith(\"https://drive.google.com/file/d/\"):\n",
        "                    !gdown -q \"{model_url}\" -O \"/content/pretrained.ckpt\" --fuzzy\n",
        "                else:\n",
        "                    !wget -q \"{model_url}\" -O \"/content/pretrained.ckpt\"\n",
        "                model_dropdown.close()\n",
        "                download_button.close()\n",
        "                output.clear()\n",
        "                if os.path.exists(\"/content/pretrained.ckpt\"):\n",
        "                    print(\"\\033[93mModel downloaded!\")\n",
        "                else:\n",
        "                    raise Exception(\"Couldn't download the pretrained model!\")\n",
        "            download_button.on_click(download_model)\n",
        "            display(model_dropdown, download_button)\n",
        "        else:\n",
        "            raise Exception(f\"There are no pretrained models available for the language {final_language}\")\n",
        "    except FileNotFoundError:\n",
        "        raise Exception(\"The pretrained_models.json file was not found.\")\n",
        "else:\n",
        "    print(\"\\033[93mWarning: this model will be trained from scratch. You need at least 8 hours of data for everything to work decent. Good luck!\")\n",
        "#@markdown ### Choose batch size based on this dataset:\n",
        "batch_size = 12 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Choose the quality for this model:\n",
        "\n",
        "#@markdown * x-low - 16Khz audio, 5-7M params\n",
        "#@markdown * medium - 22.05Khz audio, 15-20 params\n",
        "#@markdown * high - 22.05Khz audio, 28-32M params\n",
        "quality = \"medium\" #@param [\"high\", \"x-low\", \"medium\"]\n",
        "#@markdown ---\n",
        "#@markdown ### For how many epochs to save training checkpoints?\n",
        "#@markdown The larger your dataset, you should set this saving interval to a smaller value, as epochs can progress longer time.\n",
        "checkpoint_epochs = 5 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "#@markdown ### Interval to save best k models:\n",
        "#@markdown Set to 0 if you want to disable saving multiple models. If this is the case, check the checkbox below. If set to 1, models will be saved with the file name epoch=xx-step=xx.ckpt, so you will need to empty Drive's trash every so often.\n",
        "num_ckpt = 1 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "#@markdown ### Save latest model:\n",
        "#@markdown This checkbox must be checked if you want to save a single model (last.ckpt). Saving a single model is applied only if num_ckpt is equal to 0. If so, the interval parameter of epochs to save is ignored, since the last model per epoch is saved; also, you won't have to worry about storage. Being equal to 1, last.ckpt will be saved, but another model (model_vVersion.ckpt, the latter takes into account the epoch range you set), so you would have to empty the trash often.\n",
        "\n",
        "#@markdown **It's not recommended to use this option in extremely small datasets, since by saving the last model each epoch, this process will be very fast and the trainer will not be able to save the complete model, which would result in a corrupt last.ckpt.**\n",
        "save_last = False # @param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown ### Step interval to generate model samples:\n",
        "log_every_n_steps = 1000 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "#@markdown ### Training epochs:\n",
        "max_epochs = 3000 #@param {type:\"integer\"}\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MpKDfhAHjHJ3"
      },
      "outputs": [],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **5. Run the TensorBoard extension.** üìà\n",
        "#@markdown ---\n",
        "#@markdown The TensorBoard is used to visualize the results of the model while it's being trained such as audio and losses.\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {output_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lX2jSGgHC3A3",
        "outputId": "f4674db2-8bae-46b9-9f81-12d58a61b41a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (3.10.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.26.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib) (12.1.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.11/site-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuXfsKyCHrqL",
        "outputId": "41116871-4974-48cf-9992-f289321b0026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ lightning.py patched with safe indentation.\n"
          ]
        }
      ],
      "source": [
        "file_path = '/content/piper/src/python/piper_train/vits/lightning.py'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "new_lines = []\n",
        "skip_mode = False\n",
        "\n",
        "for line in lines:\n",
        "    # Identify the start of the problematic function\n",
        "    if \"def on_validation_end(self) -> None:\" in line:\n",
        "        new_lines.append(line)\n",
        "        # Inject the safe version\n",
        "        new_lines.append(\"        if self.logger is not None and hasattr(self.logger, 'experiment'):\\n\")\n",
        "        new_lines.append(\"            if hasattr(self.logger.experiment, 'add_audio'):\\n\")\n",
        "        new_lines.append(\"                for i, audio in enumerate(self.validation_outputs):\\n\")\n",
        "        new_lines.append(\"                    self.logger.experiment.add_audio(\\n\")\n",
        "        new_lines.append(\"                        f'sample_{i}',\\n\")\n",
        "        new_lines.append(\"                        audio,\\n\")\n",
        "        new_lines.append(\"                        self.global_step,\\n\")\n",
        "        new_lines.append(\"                        sample_rate=self.hparams.audio.sample_rate\\n\")\n",
        "        new_lines.append(\"                    )\\n\")\n",
        "        new_lines.append(\"        return super().on_validation_end()\\n\")\n",
        "        skip_mode = True # Skip the original lines until we hit the next function\n",
        "\n",
        "    # Stop skipping once we hit the next method or end of file\n",
        "    if skip_mode and (\"    def \" in line and \"on_validation_end\" not in line):\n",
        "        skip_mode = False\n",
        "\n",
        "    if not skip_mode:\n",
        "        new_lines.append(line)\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    f.writelines(new_lines)\n",
        "\n",
        "print(\"‚úÖ lightning.py patched with safe indentation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6RXYxOc8FgDF",
        "outputId": "202ad77d-e2e9-44b7-a4ed-7331fc22a1e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG:piper_train:Namespace(dataset_dir='/content/drive/MyDrive/colab/piper/', checkpoint_epochs=5, quality='medium', resume_from_single_speaker_checkpoint=None, batch_size=12, validation_split=0.1, num_test_examples=5, max_phoneme_ids=None, hidden_channels=192, inter_channels=192, filter_channels=768, n_layers=6, n_heads=2, lr_decay=0.999875, lr_reduce_enabled=False, lr_reduce_factor=0.5, lr_reduce_patience=10, show_plot=False, plot_save_path=None, learning_rate=0.0002, weight_decay=0.01, override_learning_rate=False, grad_clip=None, accelerator='gpu', devices=1, log_every_n_steps=10, max_epochs=3000, seed=1234, random_seed=False, resume_from_checkpoint='/content/drive/MyDrive/colab/piper/Steve/en_US-kushal-medium.ckpt', precision='32', num_ckpt=-1, default_root_dir=None, save_last=None, monitor='val_loss', monitor_mode='min', early_stop_patience=0)\n",
            "DEBUG:piper_train:Using manual seed: 1234\n",
            "DEBUG:piper_train:Checkpoints will be saved every 5 epoch(s)\n",
            "DEBUG:piper_train:-1 Checkpoints will be saved\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "  warning_cache.warn(\n",
            "/usr/local/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "DEBUG:vits.dataset:Loading dataset: /content/drive/MyDrive/colab/piper/dataset.jsonl\n",
            "Restoring states from the checkpoint path at /content/drive/MyDrive/colab/piper/Steve/en_US-kushal-medium.ckpt\n",
            "Lightning automatically upgraded your loaded checkpoint from v1.7.7 to v1.9.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../drive/MyDrive/colab/piper/Steve/en_US-kushal-medium.ckpt`\n",
            "/usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1443: UserWarning: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: [\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\"].\n",
            "  rank_zero_warn(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name    | Type                     | Params\n",
            "-----------------------------------------------------\n",
            "0 | model_g | SynthesizerTrn           | 23.7 M\n",
            "1 | model_d | MultiPeriodDiscriminator | 46.7 M\n",
            "-----------------------------------------------------\n",
            "70.4 M    Trainable params\n",
            "0         Non-trainable params\n",
            "70.4 M    Total params\n",
            "281.644   Total estimated model params size (MB)\n",
            "Restored all states from the checkpoint file at /content/drive/MyDrive/colab/piper/Steve/en_US-kushal-medium.ckpt\n",
            "Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "/usr/local/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "Epoch 2653:   0% 0/13 [00:00<?, ?it/s]             /usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
            "  warning_cache.warn(\n",
            "\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2653: 100% 13/13 [00:37<00:00,  2.88s/it, v_num=4, step=22.00]\n",
            "Epoch 2654:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=22.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2654: 100% 13/13 [00:12<00:00,  1.06it/s, v_num=4, step=44.00]\n",
            "Epoch 2655:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=44.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2655: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=66.00]\n",
            "Epoch 2656:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=66.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2656: 100% 13/13 [00:13<00:00,  1.03s/it, v_num=4, step=88.00]\n",
            "Epoch 2657:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=88.00]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2657: 100% 13/13 [00:12<00:00,  1.02it/s, v_num=4, step=110.0]\n",
            "Epoch 2658:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=110.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2658: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=132.0]\n",
            "Epoch 2659:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=132.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2659: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=154.0]\n",
            "Epoch 2660:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=154.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2660: 100% 13/13 [00:13<00:00,  1.06s/it, v_num=4, step=176.0]\n",
            "Epoch 2661:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=176.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2661: 100% 13/13 [00:13<00:00,  1.07s/it, v_num=4, step=198.0]\n",
            "Epoch 2662:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=198.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2662: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=220.0]\n",
            "Epoch 2663:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=220.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2663: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=242.0]\n",
            "Epoch 2664:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=242.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2664: 100% 13/13 [00:12<00:00,  1.00it/s, v_num=4, step=264.0]\n",
            "Epoch 2665:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=264.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2665: 100% 13/13 [00:13<00:00,  1.03s/it, v_num=4, step=286.0]\n",
            "Epoch 2666:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=286.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2666: 100% 13/13 [00:13<00:00,  1.03s/it, v_num=4, step=308.0]\n",
            "Epoch 2667:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=308.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2667: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=330.0]\n",
            "Epoch 2668:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=330.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2668: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=352.0]\n",
            "Epoch 2669:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=352.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2669: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=374.0]\n",
            "Epoch 2670:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=374.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2670: 100% 13/13 [00:13<00:00,  1.06s/it, v_num=4, step=396.0]\n",
            "Epoch 2671:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=396.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2671: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=418.0]\n",
            "Epoch 2672:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=418.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2672: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=440.0]\n",
            "Epoch 2673:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=440.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2673: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=462.0]\n",
            "Epoch 2674:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=462.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2674: 100% 13/13 [00:12<00:00,  1.00it/s, v_num=4, step=484.0]\n",
            "Epoch 2675:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=484.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2675: 100% 13/13 [00:13<00:00,  1.03s/it, v_num=4, step=506.0]\n",
            "Epoch 2676:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=506.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2676: 100% 13/13 [00:13<00:00,  1.05s/it, v_num=4, step=528.0]\n",
            "Epoch 2677:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=528.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2677: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=550.0]\n",
            "Epoch 2678:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=550.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2678: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=572.0]\n",
            "Epoch 2679:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=572.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2679: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=594.0]\n",
            "Epoch 2680:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=594.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2680: 100% 13/13 [00:13<00:00,  1.04s/it, v_num=4, step=616.0]\n",
            "Epoch 2681:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=616.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2681: 100% 13/13 [00:13<00:00,  1.02s/it, v_num=4, step=638.0]\n",
            "Epoch 2682:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=638.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2682: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=660.0]\n",
            "Epoch 2683:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=660.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2683: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=682.0]\n",
            "Epoch 2684:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=682.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2684: 100% 13/13 [00:12<00:00,  1.00it/s, v_num=4, step=704.0]\n",
            "Epoch 2685:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=704.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2685: 100% 13/13 [00:13<00:00,  1.05s/it, v_num=4, step=726.0]\n",
            "Epoch 2686:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=726.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2686: 100% 13/13 [00:13<00:00,  1.02s/it, v_num=4, step=748.0]\n",
            "Epoch 2687:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=748.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2687: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=770.0]\n",
            "Epoch 2688:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=770.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2688: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=792.0]\n",
            "Epoch 2689:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=792.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2689: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=814.0]\n",
            "Epoch 2690:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=814.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2690: 100% 13/13 [00:13<00:00,  1.05s/it, v_num=4, step=836.0]\n",
            "Epoch 2691:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=836.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2691: 100% 13/13 [00:13<00:00,  1.02s/it, v_num=4, step=858.0]\n",
            "Epoch 2692:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=858.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2692: 100% 13/13 [00:13<00:00,  1.02s/it, v_num=4, step=880.0]\n",
            "Epoch 2693:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=880.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2693: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=902.0]\n",
            "Epoch 2694:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=902.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2694: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=924.0]\n",
            "Epoch 2695:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=924.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2695: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=946.0]\n",
            "Epoch 2696:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=946.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2696: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=968.0]\n",
            "Epoch 2697:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=968.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2697: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=990.0]\n",
            "Epoch 2698:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=990.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2698: 100% 13/13 [00:12<00:00,  1.00it/s, v_num=4, step=1012.0]\n",
            "Epoch 2699:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1012.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2699: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=1034.0]\n",
            "Epoch 2700:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1034.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2700: 100% 13/13 [00:13<00:00,  1.04s/it, v_num=4, step=1056.0]\n",
            "Epoch 2701:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1056.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2701: 100% 13/13 [00:13<00:00,  1.03s/it, v_num=4, step=1078.0]\n",
            "Epoch 2702:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1078.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2702: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=1100.0]\n",
            "Epoch 2703:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1100.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2703: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=1122.0]\n",
            "Epoch 2704:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1122.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2704: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=1144.0]\n",
            "Epoch 2705:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1144.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2705: 100% 13/13 [00:13<00:00,  1.04s/it, v_num=4, step=1166.0]\n",
            "Epoch 2706:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1166.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2706: 100% 13/13 [00:13<00:00,  1.04s/it, v_num=4, step=1188.0]\n",
            "Epoch 2707:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1188.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2707: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=1210.0]\n",
            "Epoch 2708:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1210.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2708: 100% 13/13 [00:12<00:00,  1.00it/s, v_num=4, step=1232.0]\n",
            "Epoch 2709:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1232.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2709: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=1254.0]\n",
            "Epoch 2710:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1254.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2710: 100% 13/13 [00:14<00:00,  1.08s/it, v_num=4, step=1276.0]\n",
            "Epoch 2711:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1276.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2711: 100% 13/13 [00:13<00:00,  1.02s/it, v_num=4, step=1298.0]\n",
            "Epoch 2712:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1298.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2712: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=1320.0]\n",
            "Epoch 2713:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1320.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2713: 100% 13/13 [00:12<00:00,  1.00it/s, v_num=4, step=1342.0]\n",
            "Epoch 2714:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1342.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2714: 100% 13/13 [00:12<00:00,  1.00it/s, v_num=4, step=1364.0]\n",
            "Epoch 2715:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1364.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2715: 100% 13/13 [00:14<00:00,  1.08s/it, v_num=4, step=1386.0]\n",
            "Epoch 2716:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1386.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2716: 100% 13/13 [00:13<00:00,  1.02s/it, v_num=4, step=1408.0]\n",
            "Epoch 2717:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1408.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2717: 100% 13/13 [00:13<00:00,  1.02s/it, v_num=4, step=1430.0]\n",
            "Epoch 2718:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1430.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2718: 100% 13/13 [00:13<00:00,  1.02s/it, v_num=4, step=1452.0]\n",
            "Epoch 2719:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1452.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2719: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=1474.0]\n",
            "Epoch 2720:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1474.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2720: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=1496.0]\n",
            "Epoch 2721:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1496.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2721: 100% 13/13 [00:13<00:00,  1.06s/it, v_num=4, step=1518.0]\n",
            "Epoch 2722:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1518.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2722: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=1540.0]\n",
            "Epoch 2723:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1540.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2723: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=1562.0]\n",
            "Epoch 2724:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1562.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2724: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=1584.0]\n",
            "Epoch 2725:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1584.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2725: 100% 13/13 [00:13<00:00,  1.05s/it, v_num=4, step=1606.0]\n",
            "Epoch 2726:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1606.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2726: 100% 13/13 [00:13<00:00,  1.06s/it, v_num=4, step=1628.0]\n",
            "Epoch 2727:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1628.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2727: 100% 13/13 [00:13<00:00,  1.02s/it, v_num=4, step=1650.0]\n",
            "Epoch 2728:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1650.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2728: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=1672.0]\n",
            "Epoch 2729:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1672.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2729: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=1694.0]\n",
            "Epoch 2730:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1694.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2730: 100% 13/13 [00:13<00:00,  1.03s/it, v_num=4, step=1716.0]\n",
            "Epoch 2731:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1716.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2731: 100% 13/13 [00:13<00:00,  1.02s/it, v_num=4, step=1738.0]\n",
            "Epoch 2732:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1738.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2732: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=1760.0]\n",
            "Epoch 2733:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1760.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2733: 100% 13/13 [00:12<00:00,  1.00it/s, v_num=4, step=1782.0]\n",
            "Epoch 2734:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1782.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2734: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=1804.0]\n",
            "Epoch 2735:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1804.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2735: 100% 13/13 [00:13<00:00,  1.03s/it, v_num=4, step=1826.0]\n",
            "Epoch 2736:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1826.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2736: 100% 13/13 [00:13<00:00,  1.05s/it, v_num=4, step=1848.0]\n",
            "Epoch 2737:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1848.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2737: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=1870.0]\n",
            "Epoch 2738:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1870.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2738: 100% 13/13 [00:12<00:00,  1.00it/s, v_num=4, step=1892.0]\n",
            "Epoch 2739:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1892.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2739: 100% 13/13 [00:12<00:00,  1.00it/s, v_num=4, step=1914.0]\n",
            "Epoch 2740:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1914.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2740: 100% 13/13 [00:13<00:00,  1.03s/it, v_num=4, step=1936.0]\n",
            "Epoch 2741:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1936.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2741: 100% 13/13 [00:13<00:00,  1.05s/it, v_num=4, step=1958.0]\n",
            "Epoch 2742:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1958.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2742: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=1980.0]\n",
            "Epoch 2743:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=1980.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2743: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=2e+3]  \n",
            "Epoch 2744:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=2e+3]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2744: 100% 13/13 [00:13<00:00,  1.00s/it, v_num=4, step=2024.0]\n",
            "Epoch 2745:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=2024.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2745: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=2046.0]\n",
            "Epoch 2746:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=2046.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2746: 100% 13/13 [00:13<00:00,  1.06s/it, v_num=4, step=2068.0]\n",
            "Epoch 2747:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=2068.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2747: 100% 13/13 [00:13<00:00,  1.01s/it, v_num=4, step=2090.0]\n",
            "Epoch 2748:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=2090.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2748: 100% 13/13 [00:12<00:00,  1.00it/s, v_num=4, step=2112.0]\n",
            "Epoch 2749:   0% 0/13 [00:00<?, ?it/s, v_num=4, step=2112.0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2749: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=2134.0]\n",
            "Epoch 2749: 100% 13/13 [00:12<00:00,  1.01it/s, v_num=4, step=2134.0]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Force weights loading fix for PyTorch 2.6\n",
        "os.environ[\"TORCH_FORCE_WEIGHTS_ONLY_LOAD\"] = \"0\"\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/colab/piper/'\n",
        "checkpoint = '/content/drive/MyDrive/colab/piper/Steve/en_US-kushal-medium.ckpt'\n",
        "\n",
        "!python -m piper_train \\\n",
        "    --dataset-dir \"{dataset_dir}\" \\\n",
        "    --batch-size 12 \\\n",
        "    --checkpoint-epochs 5 \\\n",
        "    --quality medium \\\n",
        "    --resume_from_checkpoint \"{checkpoint}\" \\\n",
        "    --accelerator gpu \\\n",
        "    --devices 1 \\\n",
        "    --precision 32 \\\n",
        "    --log_every_n_steps 10 \\\n",
        "    --num_ckpt -1 \\\n",
        "    --max_epochs 3000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zuYYpM9TTnT",
        "outputId": "5bdb6c4e-c633-4506-ef4d-27296711d6c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "# Note: Don't do this while training is running unless you intend to stop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4zbSjXg2J3N",
        "outputId": "89cead03-fc88-4398-cd26-599f239c478e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG:piper_train:Namespace(dataset_dir='/content/drive/MyDrive/colab/piper/', checkpoint_epochs=5, quality='medium', resume_from_single_speaker_checkpoint=None, batch_size=12, validation_split=0.0, num_test_examples=0, max_phoneme_ids=None, hidden_channels=192, inter_channels=192, filter_channels=768, n_layers=6, n_heads=2, lr_decay=0.999875, lr_reduce_enabled=False, lr_reduce_factor=0.5, lr_reduce_patience=10, show_plot=False, plot_save_path=None, learning_rate=0.0002, weight_decay=0.01, override_learning_rate=False, grad_clip=None, accelerator='gpu', devices=1, log_every_n_steps=1000, max_epochs=10000, seed=1234, random_seed=False, resume_from_checkpoint='/content/pretrained.ckpt', precision='32', num_ckpt=1, default_root_dir=None, save_last=None, monitor='val_loss', monitor_mode='min', early_stop_patience=0)\n",
            "DEBUG:piper_train:Using manual seed: 1234\n",
            "DEBUG:piper_train:Checkpoints will be saved every 5 epoch(s)\n",
            "DEBUG:piper_train:1 Checkpoints will be saved\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "  warning_cache.warn(\n",
            "/usr/local/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "DEBUG:vits.dataset:Loading dataset: /content/drive/MyDrive/colab/piper/dataset.jsonl\n",
            "Missing logger folder: /content/drive/MyDrive/colab/piper/lightning_logs\n",
            "Restoring states from the checkpoint path at /content/pretrained.ckpt\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/piper/src/python/piper_train/__main__.py\", line 278, in <module>\n",
            "    main()\n",
            "  File \"/content/piper/src/python/piper_train/__main__.py\", line 255, in main\n",
            "    trainer.fit(model, ckpt_path=args.resume_from_checkpoint)\n",
            "  File \"/usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 608, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _fit_impl\n",
            "    self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"/usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1047, in _run\n",
            "    self._restore_modules_and_callbacks(ckpt_path)\n",
            "  File \"/usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 989, in _restore_modules_and_callbacks\n",
            "    self._checkpoint_connector.resume_start(checkpoint_path)\n",
            "  File \"/usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py\", line 90, in resume_start\n",
            "    loaded_checkpoint = self.trainer.strategy.load_checkpoint(checkpoint_path)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 359, in load_checkpoint\n",
            "    return self.checkpoint_io.load_checkpoint(checkpoint_path)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/lightning_fabric/plugins/io/torch_io.py\", line 86, in load_checkpoint\n",
            "    return pl_load(path, map_location=map_location)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/lightning_fabric/utilities/cloud_io.py\", line 48, in _load\n",
            "    return torch.load(f, map_location=map_location)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/torch/serialization.py\", line 1548, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL pathlib.PosixPath was not an allowed global by default. Please use `torch.serialization.add_safe_globals([pathlib.PosixPath])` or the `torch.serialization.safe_globals([pathlib.PosixPath])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n"
          ]
        }
      ],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **6. Train.** üèãÔ∏è‚Äç‚ôÇÔ∏è\n",
        "#@markdown ---\n",
        "#@markdown ### Run this cell to train your final model!\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### <font color=\"orange\">**Disable validation?**\n",
        "#@markdown By uncheck this checkbox, this will allow to train the full dataset, without using any audio files or examples as a validation set. So, it will not be able to generate audios on the tensorboard while it's training. It is recommended to disable validation on extremely small datasets.\n",
        "validation = False #@param {type:\"boolean\"}\n",
        "if validation:\n",
        "    validation_split = 0.01\n",
        "    num_test_examples = 1\n",
        "else:\n",
        "    validation_split = 0\n",
        "    num_test_examples = 0\n",
        "if not save_last:\n",
        "    save_last_command = \"\"\n",
        "else:\n",
        "    save_last_command = \"--save_last True \"\n",
        "get_ipython().system(f'''\n",
        "python -m piper_train \\\n",
        "--dataset-dir \"{output_dir}\" \\\n",
        "--accelerator 'gpu' \\\n",
        "--devices 1 \\\n",
        "--batch-size {batch_size} \\\n",
        "--validation-split {validation_split} \\\n",
        "--num-test-examples {num_test_examples} \\\n",
        "--quality {quality} \\\n",
        "--checkpoint-epochs {checkpoint_epochs} \\\n",
        "--num_ckpt {num_ckpt} \\\n",
        "{save_last_command}\\\n",
        "--log_every_n_steps {log_every_n_steps} \\\n",
        "--max_epochs {max_epochs} \\\n",
        "{ft_command}\\\n",
        "--precision 32\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ISG085SYn85"
      },
      "source": [
        "#  <font color=\"orange\">**Have you finished training and want to test the model?**\n",
        "\n",
        "* If you want to run this model in any software that Piper integrates or the same Piper app, export your model using the [model exporter notebook](https://colab.research.google.com/github/rmcpantoja/piper/blob/master/notebooks/piper_model_exporter.ipynb)!\n",
        "* Wait! I want to test this right now before exporting it to the supported format for Piper. Test your generated last.ckpt with [this notebook](https://colab.research.google.com/github/rmcpantoja/piper/blob/master/notebooks/piper_inference_(ckpt).ipynb)!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}