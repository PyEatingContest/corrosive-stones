{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Piper TTS Fine-Tuning Notebook\n",
        "\n",
        "This notebook provides a streamlined workflow for fine-tuning Piper TTS models on custom voice data.\n",
        "\n",
        "## Workflow Overview\n",
        "1. **Setup** - Downgrade Python, mount Drive, clone Piper, install dependencies\n",
        "2. **Data Preparation** - Extract audio dataset and upload transcript\n",
        "3. **Training Configuration** - Configure training settings and download pretrained model\n",
        "4. **Training** - Run fine-tuning\n",
        "5. **Export & Download** - Export to ONNX and download locally\n",
        "\n",
        "## Requirements\n",
        "- Google Colab with GPU runtime (T4 or better)\n",
        "- Audio dataset: WAV files (16000 or 22050Hz, 16-bit, mono)\n",
        "- Transcript file: `wavs/<filename>.wav|<transcription text>`\n",
        "\n",
        "## Important\n",
        "The first cell will **restart the runtime** to apply the Python downgrade. After the restart, **run the first cell again** to complete the setup.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@markdown # **1. Environment Setup**\n",
        "#@markdown ---\n",
        "#@markdown This cell sets up the complete environment:\n",
        "#@markdown - Downgrades Python to 3.10 (required for torch==2.1.0)\n",
        "#@markdown - Mounts Google Drive\n",
        "#@markdown - Clones Piper repository\n",
        "#@markdown - Builds monotonic_align extension\n",
        "#@markdown - Installs the \"Golden Trio\" dependencies for ONNX export\n",
        "#@markdown - Applies required patches\n",
        "#@markdown\n",
        "#@markdown **Note:** This cell will restart the Python runtime. After it completes, re-run this cell once more.\n",
        "\n",
        "import sys\n",
        "\n",
        "# Check if we need to downgrade Python\n",
        "if sys.version_info >= (3, 11):\n",
        "    print(\"=\"*50)\n",
        "    print(\"Downgrading Python to 3.10...\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # Downgrade Python to 3.10\n",
        "    !sudo apt-get update -qq\n",
        "    !sudo apt-get install -qq python3.10 python3.10-distutils\n",
        "    !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "    !sudo update-alternatives --set python3 /usr/bin/python3.10\n",
        "    \n",
        "    # Fix pip for Python 3.10\n",
        "    !curl -sS https://bootstrap.pypa.io/get-pip.py | python3\n",
        "    \n",
        "    # Install ipykernel for Colab runtime compatibility\n",
        "    !python3.10 -m pip install ipykernel google-colab\n",
        "    \n",
        "    print(\"\\nPython downgrade complete!\")\n",
        "    print(\"Restarting runtime...\")\n",
        "    \n",
        "    # Restart runtime\n",
        "    import os\n",
        "    os.kill(os.getpid(), 9)\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "import os\n",
        "os.environ[\"TORCH_FORCE_WEIGHTS_ONLY_LOAD\"] = \"0\"\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Clone Piper repository\n",
        "print(\"\\nCloning Piper repository...\")\n",
        "!rm -rf /content/piper\n",
        "!git clone -q https://github.com/rhasspy/piper.git /content/piper\n",
        "\n",
        "# Build monotonic_align extension\n",
        "print(\"\\nBuilding monotonic_align...\")\n",
        "%cd /content/piper/src/python\n",
        "!bash build_monotonic_align.sh 2>/dev/null\n",
        "\n",
        "# Install the \"Golden Trio\" - these specific versions are critical for ONNX export\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Installing Golden Trio dependencies...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "!pip uninstall -y torch torchvision torchaudio pytorch-lightning lightning onnxscript onnxruntime onnx -q 2>/dev/null\n",
        "!pip install torch==2.1.0 pytorch-lightning==1.9.0 torchmetrics==0.11.4 onnx==1.16.1 onnxruntime==1.17.1 -q\n",
        "\n",
        "# Install other Piper dependencies\n",
        "!pip install -q cython piper-phonemize==1.1.0 librosa numpy==1.26\n",
        "\n",
        "# Apply patches for ONNX export compatibility\n",
        "print(\"\\nApplying ONNX export patches...\")\n",
        "\n",
        "# Patch 1: Comment out math assertion in transforms.py\n",
        "!sed -i 's/assert (discriminant >= 0).all(), discriminant/# assert (discriminant >= 0).all(), discriminant/' /content/piper/src/python/piper_train/vits/transforms.py\n",
        "\n",
        "# Patch 2: Add .detach() to mask guard in modules.py\n",
        "!sed -i 's/h = self.pre(x0) \\* x_mask/h = self.pre(x0) * x_mask.detach()/' /content/piper/src/python/piper_train/vits/modules.py\n",
        "\n",
        "# Setup PyTorch serialization for Piper checkpoints\n",
        "import torch\n",
        "import pathlib\n",
        "torch.serialization.add_safe_globals([pathlib.PosixPath, pathlib.PurePosixPath])\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Setup complete!\")\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@markdown # **2. Extract Dataset**\n",
        "#@markdown ---\n",
        "#@markdown Extract your audio dataset from a ZIP file on Google Drive.\n",
        "#@markdown\n",
        "#@markdown **Audio Requirements:**\n",
        "#@markdown - WAV format\n",
        "#@markdown - 16000 or 22050Hz sample rate\n",
        "#@markdown - 16-bit, mono\n",
        "#@markdown - Numbered files: 1.wav, 2.wav, 3.wav, ...\n",
        "\n",
        "import os\n",
        "import wave\n",
        "import zipfile\n",
        "import datetime\n",
        "\n",
        "def get_dataset_duration(wav_path):\n",
        "    \"\"\"Calculate total duration and count of WAV files.\"\"\"\n",
        "    totalduration = 0\n",
        "    wav_files = [x for x in os.listdir(wav_path) if x.endswith(\".wav\")]\n",
        "    for file_name in wav_files:\n",
        "        file_path = os.path.join(wav_path, file_name)\n",
        "        try:\n",
        "            with wave.open(file_path, \"rb\") as wave_file:\n",
        "                frames = wave_file.getnframes()\n",
        "                rate = wave_file.getframerate()\n",
        "                duration = frames / float(rate)\n",
        "                totalduration += duration\n",
        "        except:\n",
        "            pass\n",
        "    duration_str = str(datetime.timedelta(seconds=round(totalduration, 0)))\n",
        "    return len(wav_files), duration_str\n",
        "\n",
        "# Create dataset directories\n",
        "%cd /content\n",
        "!rm -rf /content/dataset\n",
        "os.makedirs(\"/content/dataset/wavs\", exist_ok=True)\n",
        "%cd /content/dataset\n",
        "\n",
        "#@markdown ### Path to your audio dataset ZIP file:\n",
        "zip_path = \"/content/drive/MyDrive/piper_dataset.zip\" #@param {type:\"string\"}\n",
        "\n",
        "zip_path = zip_path.strip()\n",
        "if not zip_path:\n",
        "    raise Exception(\"You must provide a path to your audio dataset.\")\n",
        "\n",
        "if not os.path.exists(zip_path):\n",
        "    raise Exception(f\"Path not found: {zip_path}\")\n",
        "\n",
        "if zipfile.is_zipfile(zip_path):\n",
        "    print(\"Extracting audio files...\")\n",
        "    !unzip -q -j \"{zip_path}\" -d /content/dataset/wavs\n",
        "else:\n",
        "    print(\"Copying audio files from folder...\")\n",
        "    !cp -a \"{zip_path}/.\" /content/dataset/wavs/\n",
        "\n",
        "# Handle nested wavs folder if present\n",
        "if os.path.exists(\"/content/dataset/wavs/wavs\"):\n",
        "    !mv /content/dataset/wavs/wavs/* /content/dataset/wavs/\n",
        "    !rm -rf /content/dataset/wavs/wavs\n",
        "\n",
        "# Remove any text files that came with the ZIP\n",
        "!rm -f /content/dataset/wavs/*.txt /content/dataset/wavs/*.csv 2>/dev/null\n",
        "\n",
        "# Report dataset info\n",
        "audio_count, dataset_dur = get_dataset_duration(\"/content/dataset/wavs\")\n",
        "print(f\"\\nDataset loaded: {audio_count} WAV files, total duration: {dataset_dur}\")\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@markdown # **3. Upload Transcript & Preprocess**\n",
        "#@markdown ---\n",
        "#@markdown Upload your transcript file and preprocess the dataset.\n",
        "#@markdown\n",
        "#@markdown **Transcript Format (single-speaker):**\n",
        "#@markdown ```\n",
        "#@markdown wavs/1.wav|This is the text spoken in audio 1.\n",
        "#@markdown wavs/2.wav|This is the text spoken in audio 2.\n",
        "#@markdown ```\n",
        "#@markdown\n",
        "#@markdown **Transcript Format (multi-speaker):**\n",
        "#@markdown ```\n",
        "#@markdown wavs/1.wav|speaker1|Text spoken by speaker 1.\n",
        "#@markdown wavs/2.wav|speaker2|Text spoken by speaker 2.\n",
        "#@markdown ```\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown ### Language of your dataset:\n",
        "language = \"English (U.S.)\" #@param [\"English (British)\", \"English (U.S.)\", \"Deutsch\", \"Fran\\u00e7ais\", \"Espa\\u00f1ol (Castellano)\", \"Espa\\u00f1ol (Latinoamericano)\", \"Italiano\", \"Portugu\\u00eas (Brasil)\", \"Portugu\\u00eas (Portugal)\", \"Nederlands\", \"Polski\", \"\u0420\u0443\u0441\u0441\u043a\u0438\u0439\", \"\\u7b80\\u4f53\\u4e2d\\u6587\", \"\\u65e5\\u672c\\u8a9e\"]\n",
        "\n",
        "#@markdown ### Model name (no spaces):\n",
        "model_name = \"my_voice\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Output folder (save to Drive recommended):\n",
        "output_path = \"/content/drive/MyDrive/colab/piper\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Sample rate of your audio files:\n",
        "sample_rate = \"22050\" #@param [\"16000\", \"22050\"]\n",
        "\n",
        "#@markdown ### Single speaker dataset?\n",
        "single_speaker = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Language code mapping\n",
        "languages = {\n",
        "    \"English (British)\": \"en\",\n",
        "    \"English (U.S.)\": \"en-us\",\n",
        "    \"Deutsch\": \"de\",\n",
        "    \"Fran\\u00e7ais\": \"fr\",\n",
        "    \"Espa\\u00f1ol (Castellano)\": \"es\",\n",
        "    \"Espa\\u00f1ol (Latinoamericano)\": \"es-419\",\n",
        "    \"Italiano\": \"it\",\n",
        "    \"Portugu\\u00eas (Brasil)\": \"pt-br\",\n",
        "    \"Portugu\\u00eas (Portugal)\": \"pt-pt\",\n",
        "    \"Nederlands\": \"nl\",\n",
        "    \"Polski\": \"pl\",\n",
        "    \"\u0420\u0443\u0441\u0441\u043a\u0438\u0439\": \"ru\",\n",
        "    \"\\u7b80\\u4f53\\u4e2d\\u6587\": \"zh\",\n",
        "    \"\\u65e5\\u672c\\u8a9e\": \"ja\"\n",
        "}\n",
        "\n",
        "final_language = languages[language]\n",
        "output_dir = os.path.join(output_path, model_name)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Upload transcript\n",
        "%cd /content/dataset\n",
        "!rm -f /content/dataset/metadata.csv\n",
        "\n",
        "print(\"Please upload your transcript file (metadata.csv or .txt):\")\n",
        "uploaded = files.upload()\n",
        "uploaded_filename = list(uploaded.keys())[0]\n",
        "if uploaded_filename != \"metadata.csv\":\n",
        "    !mv \"{uploaded_filename}\" metadata.csv\n",
        "\n",
        "# Create audio cache directory\n",
        "os.makedirs(\"/content/audio_cache\", exist_ok=True)\n",
        "\n",
        "# Run preprocessing\n",
        "%cd /content/piper/src/python\n",
        "\n",
        "force_sp = \"--single-speaker\" if single_speaker else \"\"\n",
        "\n",
        "print(\"\\nRunning preprocessing...\")\n",
        "!python -m piper_train.preprocess \\\n",
        "  --language {final_language} \\\n",
        "  --input-dir /content/dataset \\\n",
        "  --cache-dir \"/content/audio_cache\" \\\n",
        "  --output-dir \"{output_dir}\" \\\n",
        "  --dataset-name \"{model_name}\" \\\n",
        "  --dataset-format ljspeech \\\n",
        "  --sample-rate {sample_rate} \\\n",
        "  {force_sp}\n",
        "\n",
        "print(\"\\nPreprocessing complete!\")\n",
        "print(f\"Output directory: {output_dir}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@markdown # **4. Training Settings**\n",
        "#@markdown ---\n",
        "#@markdown Configure training hyperparameters.\n",
        "\n",
        "#@markdown ### Batch size:\n",
        "#@markdown Reduce if you run out of GPU memory.\n",
        "batch_size = 12 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Model quality:\n",
        "#@markdown - **x-low**: 16KHz, 5-7M params (fastest)\n",
        "#@markdown - **medium**: 22.05KHz, 15-20M params (recommended)\n",
        "#@markdown - **high**: 22.05KHz, 28-32M params (best quality)\n",
        "quality = \"medium\" #@param [\"x-low\", \"medium\", \"high\"]\n",
        "\n",
        "#@markdown ### Maximum training epochs:\n",
        "max_epochs = 3000 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Checkpoint save interval (epochs):\n",
        "checkpoint_epochs = 5 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Enable validation?\n",
        "#@markdown Disable for very small datasets (<5 min audio).\n",
        "enable_validation = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Log interval (steps):\n",
        "log_every_n_steps = 1000 #@param {type:\"integer\"}\n",
        "\n",
        "# Store settings for training cell\n",
        "training_settings = {\n",
        "    'batch_size': batch_size,\n",
        "    'quality': quality,\n",
        "    'max_epochs': max_epochs,\n",
        "    'checkpoint_epochs': checkpoint_epochs,\n",
        "    'enable_validation': enable_validation,\n",
        "    'log_every_n_steps': log_every_n_steps\n",
        "}\n",
        "\n",
        "print(\"Training settings configured:\")\n",
        "for key, value in training_settings.items():\n",
        "    print(f\"  {key}: {value}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@markdown # **5. Download Pretrained Model**\n",
        "#@markdown ---\n",
        "#@markdown Download a pretrained model to fine-tune.\n",
        "#@markdown\n",
        "#@markdown Select a model that matches your target language.\n",
        "\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from google.colab import output\n",
        "import os\n",
        "\n",
        "# Load pretrained models list\n",
        "try:\n",
        "    with open('/content/piper/notebooks/pretrained_models.json') as f:\n",
        "        pretrained_models = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    raise Exception(\"pretrained_models.json not found. Run Setup cell first.\")\n",
        "\n",
        "if final_language not in pretrained_models:\n",
        "    print(f\"No pretrained models available for {final_language}.\")\n",
        "    print(\"Available languages:\", list(pretrained_models.keys()))\n",
        "    raise Exception(f\"Please choose a different language or provide your own checkpoint.\")\n",
        "\n",
        "models = pretrained_models[final_language]\n",
        "model_options = [(name, name) for name in models.keys()]\n",
        "\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    description=\"Model:\",\n",
        "    options=model_options,\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "download_button = widgets.Button(description=\"Download Model\", button_style='primary')\n",
        "status_output = widgets.Output()\n",
        "\n",
        "def download_model(btn):\n",
        "    with status_output:\n",
        "        status_output.clear_output()\n",
        "        selected_model = model_dropdown.value\n",
        "        model_url = pretrained_models[final_language][selected_model]\n",
        "        print(f\"Downloading {selected_model}...\")\n",
        "        \n",
        "        !rm -f /content/pretrained.ckpt\n",
        "        \n",
        "        if model_url.startswith(\"1\"):\n",
        "            # Google Drive file ID\n",
        "            !gdown -q \"{model_url}\" -O \"/content/pretrained.ckpt\"\n",
        "        elif \"drive.google.com\" in model_url:\n",
        "            !gdown -q \"{model_url}\" -O \"/content/pretrained.ckpt\" --fuzzy\n",
        "        else:\n",
        "            !wget -q \"{model_url}\" -O \"/content/pretrained.ckpt\"\n",
        "        \n",
        "        if os.path.exists(\"/content/pretrained.ckpt\"):\n",
        "            size_mb = os.path.getsize(\"/content/pretrained.ckpt\") / (1024 * 1024)\n",
        "            print(f\"\\nDownload complete! ({size_mb:.1f} MB)\")\n",
        "            print(\"Pretrained model saved to: /content/pretrained.ckpt\")\n",
        "        else:\n",
        "            print(\"\\nError: Download failed. Please try again.\")\n",
        "\n",
        "download_button.on_click(download_model)\n",
        "\n",
        "print(f\"Available pretrained models for {language}:\\n\")\n",
        "display(model_dropdown, download_button, status_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@markdown # **6. Run Fine-Tuning**\n",
        "#@markdown ---\n",
        "#@markdown Start training! Monitor progress in the output.\n",
        "#@markdown\n",
        "#@markdown **Tips:**\n",
        "#@markdown - Training can take several hours depending on dataset size\n",
        "#@markdown - Checkpoints are saved to Google Drive automatically\n",
        "#@markdown - You can stop and resume training later\n",
        "\n",
        "import os\n",
        "\n",
        "# Verify pretrained model exists\n",
        "if not os.path.exists(\"/content/pretrained.ckpt\"):\n",
        "    raise Exception(\"Pretrained model not found! Run the 'Download Pretrained Model' cell first.\")\n",
        "\n",
        "# Set validation parameters\n",
        "if training_settings['enable_validation']:\n",
        "    validation_split = 0.01\n",
        "    num_test_examples = 1\n",
        "else:\n",
        "    validation_split = 0\n",
        "    num_test_examples = 0\n",
        "\n",
        "print(f\"Starting fine-tuning...\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"Quality: {training_settings['quality']}\")\n",
        "print(f\"Max epochs: {training_settings['max_epochs']}\")\n",
        "print(f\"Batch size: {training_settings['batch_size']}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "%cd /content/piper/src/python\n",
        "\n",
        "!python -m piper_train \\\n",
        "  --dataset-dir \"{output_dir}\" \\\n",
        "  --accelerator 'gpu' \\\n",
        "  --devices 1 \\\n",
        "  --batch-size {training_settings['batch_size']} \\\n",
        "  --validation-split {validation_split} \\\n",
        "  --num-test-examples {num_test_examples} \\\n",
        "  --quality {training_settings['quality']} \\\n",
        "  --checkpoint-epochs {training_settings['checkpoint_epochs']} \\\n",
        "  --num_ckpt 1 \\\n",
        "  --log_every_n_steps {training_settings['log_every_n_steps']} \\\n",
        "  --max_epochs {training_settings['max_epochs']} \\\n",
        "  --resume_from_checkpoint \"/content/pretrained.ckpt\" \\\n",
        "  --precision 32\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training complete!\")\n",
        "print(\"=\"*50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@markdown # **7. Export to ONNX**\n",
        "#@markdown ---\n",
        "#@markdown Export your trained model to ONNX format for inference.\n",
        "#@markdown\n",
        "#@markdown This cell auto-detects the latest checkpoint, or you can specify one.\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "\n",
        "#@markdown ### Checkpoint path (leave empty to auto-detect latest):\n",
        "checkpoint_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Output ONNX filename (without extension):\n",
        "output_name = \"my_voice\" #@param {type:\"string\"}\n",
        "\n",
        "# Auto-detect latest checkpoint if not specified\n",
        "if not checkpoint_path:\n",
        "    checkpoints = glob.glob(f\"{output_dir}/lightning_logs/**/checkpoints/*.ckpt\", recursive=True)\n",
        "    if not checkpoints:\n",
        "        raise Exception(f\"No checkpoints found in {output_dir}/lightning_logs/\")\n",
        "    \n",
        "    # Sort by version number and epoch\n",
        "    def get_checkpoint_info(path):\n",
        "        version_match = re.search(r'version_(\\d+)', path)\n",
        "        epoch_match = re.search(r'epoch=(\\d+)', path)\n",
        "        version = int(version_match.group(1)) if version_match else 0\n",
        "        epoch = int(epoch_match.group(1)) if epoch_match else 0\n",
        "        return (version, epoch)\n",
        "    \n",
        "    checkpoints.sort(key=get_checkpoint_info, reverse=True)\n",
        "    checkpoint_path = checkpoints[0]\n",
        "    print(f\"Auto-detected checkpoint: {checkpoint_path}\")\n",
        "\n",
        "# Verify checkpoint exists\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    raise Exception(f\"Checkpoint not found: {checkpoint_path}\")\n",
        "\n",
        "# Set output paths\n",
        "output_onnx = f\"{output_dir}/{output_name}.onnx\"\n",
        "config_path = f\"{output_dir}/config.json\"\n",
        "\n",
        "print(f\"\\nExporting to ONNX...\")\n",
        "print(f\"Checkpoint: {checkpoint_path}\")\n",
        "print(f\"Output: {output_onnx}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "%cd /content/piper/src/python\n",
        "\n",
        "!python3 -m piper_train.export_onnx \\\n",
        "    \"{checkpoint_path}\" \\\n",
        "    \"{output_onnx}\"\n",
        "\n",
        "# Copy config file\n",
        "if os.path.exists(config_path):\n",
        "    !cp \"{config_path}\" \"{output_onnx}.json\"\n",
        "    print(f\"\\nConfig copied to: {output_onnx}.json\")\n",
        "\n",
        "# Verify export\n",
        "if os.path.exists(output_onnx):\n",
        "    size_mb = os.path.getsize(output_onnx) / (1024 * 1024)\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Export successful!\")\n",
        "    print(f\"ONNX model: {output_onnx} ({size_mb:.1f} MB)\")\n",
        "    print(f\"Config: {output_onnx}.json\")\n",
        "    print(\"=\"*50)\n",
        "else:\n",
        "    print(\"\\nError: Export failed. Check the output above for errors.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@markdown # **8. Download Model**\n",
        "#@markdown ---\n",
        "#@markdown Download the exported ONNX model and config to your local computer.\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Get the ONNX file path from previous cell\n",
        "onnx_path = f\"{output_dir}/{output_name}.onnx\"\n",
        "config_path = f\"{onnx_path}.json\"\n",
        "\n",
        "print(\"Preparing files for download...\\n\")\n",
        "\n",
        "# Download ONNX model\n",
        "if os.path.exists(onnx_path):\n",
        "    print(f\"Downloading: {os.path.basename(onnx_path)}\")\n",
        "    files.download(onnx_path)\n",
        "else:\n",
        "    print(f\"Error: ONNX file not found at {onnx_path}\")\n",
        "    print(\"Please run the Export cell first.\")\n",
        "\n",
        "# Download config\n",
        "if os.path.exists(config_path):\n",
        "    print(f\"Downloading: {os.path.basename(config_path)}\")\n",
        "    files.download(config_path)\n",
        "else:\n",
        "    print(f\"Warning: Config file not found at {config_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Usage Instructions**\n",
        "\n",
        "After downloading your model files, you can use them with Piper TTS:\n",
        "\n",
        "## Installation\n",
        "\n",
        "```bash\n",
        "pip install piper-tts\n",
        "```\n",
        "\n",
        "## Command Line Usage\n",
        "\n",
        "```bash\n",
        "echo \"Hello, this is my custom voice!\" | piper \\\n",
        "    --model my_voice.onnx \\\n",
        "    --config my_voice.onnx.json \\\n",
        "    --output_file output.wav\n",
        "```\n",
        "\n",
        "## Python Usage\n",
        "\n",
        "```python\n",
        "from piper import PiperVoice\n",
        "\n",
        "voice = PiperVoice.load(\"my_voice.onnx\", \"my_voice.onnx.json\")\n",
        "\n",
        "with open(\"output.wav\", \"wb\") as f:\n",
        "    voice.synthesize(\"Hello, this is my custom voice!\", f)\n",
        "```\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [Piper GitHub](https://github.com/rhasspy/piper)\n",
        "- [Piper Documentation](https://github.com/rhasspy/piper/blob/master/TRAINING.md)\n",
        "- [Piper Samples](https://rhasspy.github.io/piper-samples/)\n",
        "\n",
        "---\n",
        "\n",
        "*Happy voice cloning!*"
      ]
    }
  ]
}