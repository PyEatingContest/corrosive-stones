{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Piper TTS Preprocessing Notebook\n",
        "\n",
        "This notebook preprocesses audio data for Piper TTS training.\n",
        "\n",
        "## What This Does\n",
        "1. Sets up the environment with Python 3.10\n",
        "2. Preprocesses your audio dataset (creates phoneme mappings and audio tensors)\n",
        "3. Saves preprocessed data to Google Drive\n",
        "\n",
        "## Requirements\n",
        "- Audio files: WAV format (22050Hz, 16-bit, mono) in a `wavs/` folder\n",
        "- Transcript file: `metadata.csv` with format `wavs/filename.wav|Text spoken in audio`\n",
        "\n",
        "## Important\n",
        "Run Cell 1 **twice** - it will restart the kernel after installing condacolab.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@markdown # **1. Environment Setup**\n",
        "#@markdown ---\n",
        "#@markdown Run this cell **twice**. First run installs condacolab and restarts the kernel.\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Check if condacolab is set up\n",
        "try:\n",
        "    import condacolab\n",
        "    condacolab.check()\n",
        "    print(f\"Condacolab ready! Python: {sys.version}\")\n",
        "except:\n",
        "    print(\"Installing condacolab...\")\n",
        "    !pip install -q condacolab\n",
        "    import condacolab\n",
        "    condacolab.install()  # Restarts kernel\n",
        "\n",
        "# Install Python 3.10 if needed\n",
        "if sys.version_info >= (3, 11):\n",
        "    print(\"Installing Python 3.10...\")\n",
        "    !rm -f /usr/local/conda-meta/pinned\n",
        "    !conda install -y python=3.10 --override-channels -c conda-forge -q\n",
        "    print(\"Restarting...\")\n",
        "    os.kill(os.getpid(), 9)\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Clone Piper\n",
        "print(\"\\nCloning Piper...\")\n",
        "!rm -rf /content/piper\n",
        "!git clone -q https://github.com/rhasspy/piper.git /content/piper\n",
        "\n",
        "# Install dependencies for preprocessing\n",
        "print(\"\\nInstalling dependencies...\")\n",
        "!pip install -q cython piper-phonemize==1.1.0 librosa numpy==1.26\n",
        "\n",
        "# Build monotonic_align\n",
        "%cd /content/piper/src/python\n",
        "!bash build_monotonic_align.sh 2>/dev/null\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Setup complete!\")\n",
        "print(\"=\"*50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@markdown # **2. Preprocess Dataset**\n",
        "#@markdown ---\n",
        "#@markdown Configure paths and run preprocessing.\n",
        "#@markdown\n",
        "#@markdown **Your Google Drive should have:**\n",
        "#@markdown ```\n",
        "#@markdown /MyDrive/colab/piper/\n",
        "#@markdown   wavs/\n",
        "#@markdown     0000000001.wav\n",
        "#@markdown     0000000002.wav\n",
        "#@markdown     ...\n",
        "#@markdown   metadata.csv\n",
        "#@markdown ```\n",
        "\n",
        "import os\n",
        "\n",
        "#@markdown ### Input folder (contains wavs/ and metadata.csv):\n",
        "input_dir = \"/content/drive/MyDrive/colab/piper\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Output folder (preprocessed data saved here):\n",
        "output_dir = \"/content/drive/MyDrive/colab/piper/Steve\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Model name:\n",
        "model_name = \"Steve\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Language:\n",
        "language = \"en-us\" #@param [\"en-us\", \"en\", \"de\", \"fr\", \"es\", \"it\", \"pt-br\", \"nl\", \"pl\", \"ru\", \"zh\"]\n",
        "\n",
        "#@markdown ### Sample rate:\n",
        "sample_rate = \"22050\" #@param [\"16000\", \"22050\"]\n",
        "\n",
        "#@markdown ### Single speaker dataset?\n",
        "single_speaker = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Verify input exists\n",
        "wavs_dir = os.path.join(input_dir, \"wavs\")\n",
        "metadata_file = os.path.join(input_dir, \"metadata.csv\")\n",
        "\n",
        "if not os.path.exists(wavs_dir):\n",
        "    raise Exception(f\"wavs folder not found: {wavs_dir}\")\n",
        "if not os.path.exists(metadata_file):\n",
        "    raise Exception(f\"metadata.csv not found: {metadata_file}\")\n",
        "\n",
        "wav_count = len([f for f in os.listdir(wavs_dir) if f.endswith('.wav')])\n",
        "print(f\"Found {wav_count} WAV files\")\n",
        "print(f\"Output will be saved to: {output_dir}\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Create audio cache directory\n",
        "cache_dir = \"/content/audio_cache\"\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "# Build command\n",
        "speaker_flag = \"--single-speaker\" if single_speaker else \"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Running preprocessing...\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "%cd /content/piper/src/python\n",
        "\n",
        "!python -m piper_train.preprocess \\\n",
        "    --language {language} \\\n",
        "    --input-dir \"{input_dir}\" \\\n",
        "    --output-dir \"{output_dir}\" \\\n",
        "    --dataset-name \"{model_name}\" \\\n",
        "    --dataset-format ljspeech \\\n",
        "    --sample-rate {sample_rate} \\\n",
        "    --cache-dir \"{cache_dir}\" \\\n",
        "    {speaker_flag}\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Preprocessing complete!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nOutput saved to: {output_dir}\")\n",
        "print(\"\\nFiles created:\")\n",
        "!ls -la \"{output_dir}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@markdown # **3. Verify Preprocessing**\n",
        "#@markdown ---\n",
        "#@markdown Check that all required files were created.\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "print(\"Checking preprocessed output...\\n\")\n",
        "\n",
        "# Check config.json\n",
        "config_path = os.path.join(output_dir, \"config.json\")\n",
        "if os.path.exists(config_path):\n",
        "    print(\"[OK] config.json exists\")\n",
        "    with open(config_path) as f:\n",
        "        config = json.load(f)\n",
        "        print(f\"     Sample rate: {config.get('audio', {}).get('sample_rate', 'N/A')}\")\n",
        "else:\n",
        "    print(\"[ERROR] config.json missing!\")\n",
        "\n",
        "# Check dataset.jsonl\n",
        "dataset_path = os.path.join(output_dir, \"dataset.jsonl\")\n",
        "if os.path.exists(dataset_path):\n",
        "    with open(dataset_path) as f:\n",
        "        lines = f.readlines()\n",
        "    print(f\"[OK] dataset.jsonl exists ({len(lines)} entries)\")\n",
        "    \n",
        "    # Check first entry for required fields\n",
        "    first = json.loads(lines[0])\n",
        "    has_audio_norm = \"audio_norm_path\" in first\n",
        "    has_phoneme_ids = \"phoneme_ids\" in first\n",
        "    print(f\"     Has audio_norm_path: {has_audio_norm}\")\n",
        "    print(f\"     Has phoneme_ids: {has_phoneme_ids}\")\n",
        "    \n",
        "    if not has_audio_norm:\n",
        "        print(\"\\n[WARNING] audio_norm_path missing - audio cache may not have been created\")\n",
        "else:\n",
        "    print(\"[ERROR] dataset.jsonl missing!\")\n",
        "\n",
        "# Check audio cache\n",
        "audio_dir = os.path.join(output_dir, \"audio\")\n",
        "if os.path.exists(audio_dir):\n",
        "    pt_files = [f for f in os.listdir(audio_dir) if f.endswith('.pt')]\n",
        "    print(f\"[OK] audio/ folder exists ({len(pt_files)} .pt files)\")\n",
        "else:\n",
        "    # Check cache dir\n",
        "    if os.path.exists(cache_dir):\n",
        "        pt_files = [f for f in os.listdir(cache_dir) if f.endswith('.pt')]\n",
        "        if pt_files:\n",
        "            print(f\"[INFO] Audio cache in {cache_dir} ({len(pt_files)} .pt files)\")\n",
        "            print(\"       Copying to output directory...\")\n",
        "            !cp -r \"{cache_dir}\" \"{output_dir}/audio\"\n",
        "            print(\"       Done!\")\n",
        "        else:\n",
        "            print(\"[WARNING] No .pt files found in cache\")\n",
        "    else:\n",
        "        print(\"[WARNING] audio/ folder missing!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Verification complete!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nYour preprocessed data is at: {output_dir}\")\n",
        "print(\"Sync this folder to your Mac for local training.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
